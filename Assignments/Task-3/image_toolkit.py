# -*- coding: utf-8 -*-
"""Image toolkit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VRLSphrfJonRmAa4SK78eusxuiigTdiQ

**Objective**

To design and implement a system design: GUI-based application in Python that demonstrates fundamental Image Processing operations using OpenCV.

This project will not just cover the theory (filters, transforms, compression, etc.) but also provide a hands-on GUI where users can upload an image, apply operations, and visualize results side-by-side interactively.

üìç GUI Layout (Streamlit Design)
1. Menu Bar (Top Section)
File

Open ‚Üí Upload an image from local system
Save ‚Üí Save processed image
Exit ‚Üí Close/quit app
"""

pip install Streamlit

import streamlit as st
from PIL import Image

st.set_page_config(layout="wide")

st.title("Image Processing Application")

# Menu Bar
st.sidebar.title("Menu")

# File operations
file_operation = st.sidebar.selectbox("File", ["", "Open", "Save", "Exit"])

if file_operation == "Open":
    uploaded_file = st.sidebar.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"])
    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        st.image(image, caption="Uploaded Image", use_column_width=True)
elif file_operation == "Save":
    st.sidebar.write("Save functionality will be implemented later.")
elif file_operation == "Exit":
    st.sidebar.write("Exit functionality will be implemented later.")

# Main content area (for displaying images and results)
st.subheader("Image Display Area")

"""# Task
Generate Python code using the Streamlit and OpenCV libraries to create a GUI application for image processing. The application should have a menu bar with "File" options (Open, Save, Exit) and a sidebar with sections for various image operations: Image Info (resolution, shape, DPI, format, channels), Color Conversions (RGB ‚Üî BGR, RGB ‚Üî HSV, RGB ‚Üî YCbCr, RGB ‚Üî Grayscale), Transformations (Rotation, Scaling, Translation, Affine, Perspective), Filtering & Morphology (Gaussian, Mean, Median, Sobel, Laplacian, Dilation, Erosion, Opening, Closing), Enhancement (Histogram Equalization, Contrast Stretching, Sharpening), Edge Detection (Sobel, Canny, Laplacian), and Compression (JPG, PNG, BMP saving with size/quality comparison). The application should display the original and processed images.

## Add image info section

### Subtask:
Implement the functionality to display image resolution, shape, DPI, file format, and color channels in the sidebar.

**Reasoning**:
Implement the "Image Info" section in the sidebar to display image properties like resolution, shape, DPI, format, and channels using the loaded image object.
"""

import streamlit as st
from PIL import Image
import numpy as np

st.set_page_config(layout="wide")

st.title("Image Processing Application")

# Menu Bar
st.sidebar.title("Menu")

# File operations
file_operation = st.sidebar.selectbox("File", ["", "Open", "Save", "Exit"])

image = None  # Initialize image variable outside the conditional block

if file_operation == "Open":
    uploaded_file = st.sidebar.file_uploader("Choose an image...", type=["jpg", "jpeg", "png", "bmp", "tiff"])
    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        st.image(image, caption="Uploaded Image", use_column_width=True)
elif file_operation == "Save":
    st.sidebar.write("Save functionality will be implemented later.")
elif file_operation == "Exit":
    st.sidebar.write("Exit functionality will be implemented later.")

# Main content area (for displaying images and results)
st.subheader("Image Display Area")

# Image Info Section
st.sidebar.title("Image Info")

if image is not None:
    st.sidebar.write(f"Resolution: {image.width} x {image.height}")
    st.sidebar.write(f"Shape: {np.array(image).shape}")
    if image.info and 'dpi' in image.info:
        st.sidebar.write(f"DPI: {image.info['dpi']}")
    else:
        st.sidebar.write("DPI: N/A")
    st.sidebar.write(f"Format: {image.format}")
    st.sidebar.write(f"Channels: {len(image.getbands())}")
else:
    st.sidebar.write("No image loaded yet.")

"""## Add color conversion section

### Subtask:
Add options in the sidebar for different color conversions (RGB ‚Üî BGR, RGB ‚Üî HSV, RGB ‚Üî YCbCr, RGB ‚Üî Grayscale) and implement the corresponding OpenCV code.

**Reasoning**:
Implement the color conversion section in the sidebar with selectbox options and the corresponding OpenCV color conversion logic, handling the conversion between PIL Image and OpenCV numpy arrays and displaying the original and processed images side-by-side using Streamlit columns.
"""

import cv2

# Color Conversions Section
st.sidebar.title("Color Conversions")
color_conversion = st.sidebar.selectbox("Select Conversion", ["None", "RGB to BGR", "BGR to RGB", "RGB to HSV", "HSV to RGB", "RGB to YCbCr", "YCbCr to RGB", "RGB to Grayscale"])

processed_image = None

if image is not None:
    img_array = np.array(image)

    # Convert RGB (Pillow default) to BGR (OpenCV default) for processing
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)

    if color_conversion == "RGB to BGR":
        # Already in BGR for processing, no extra step needed here for display
        processed_image_array = img_array_bgr
    elif color_conversion == "BGR to RGB":
        processed_image_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2RGB)
    elif color_conversion == "RGB to HSV":
        processed_image_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2HSV)
    elif color_conversion == "HSV to RGB":
        # Need to convert back from BGR to HSV first, then HSV to RGB
        img_array_hsv = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2HSV)
        processed_image_array = cv2.cvtColor(img_array_hsv, cv2.COLOR_HSV2RGB)
    elif color_conversion == "RGB to YCbCr":
        processed_image_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2YCR_CB)
    elif color_conversion == "YCbCr to RGB":
        # Need to convert back from BGR to YCbCr first, then YCbCr to RGB
        img_array_ycbcr = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2YCR_CB)
        processed_image_array = cv2.cvtColor(img_array_ycbcr, cv2.COLOR_YCR_CB2RGB)
    elif color_conversion == "RGB to Grayscale":
        processed_image_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2GRAY)
        # Convert grayscale numpy array back to PIL Image
        processed_image = Image.fromarray(processed_image_array, 'L') # 'L' mode for grayscale
    elif color_conversion == "None":
        processed_image_array = img_array

    if processed_image is None: # If not grayscale which was handled above
        processed_image = Image.fromarray(processed_image_array)


# Display images side-by-side
if image is not None:
    col1, col2 = st.columns(2)
    with col1:
        st.image(image, caption="Original Image", use_column_width=True)
    with col2:
        if processed_image is not None:
            st.image(processed_image, caption=f"Processed Image ({color_conversion})", use_column_width=True)
        else:
            st.write("Select a color conversion to see the processed image.")

"""## Add transformations section

### Subtask:
Include options for geometric transformations (Rotation, Scaling, Translation, Affine Transform, Perspective Transform) and implement the OpenCV code.

**Reasoning**:
Add a new section for "Transformations" in the sidebar with a selectbox for different transformation types.
"""

import cv2
import numpy as np
from PIL import Image

# Transformations Section
st.sidebar.title("Transformations")
transformation_type = st.sidebar.selectbox("Select Transformation", ["None", "Rotation", "Scaling", "Translation", "Affine Transform", "Perspective Transform"])

transformed_image = None

if image is not None:
    img_array = np.array(image)
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)

    rows, cols, _ = img_array_bgr.shape

    if transformation_type == "Rotation":
        angle = st.sidebar.slider("Angle (degrees)", -180, 180, 0)
        M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)
        transformed_img_array = cv2.warpAffine(img_array_bgr, M, (cols, rows))
        transformed_image = Image.fromarray(cv2.cvtColor(transformed_img_array, cv2.COLOR_BGR2RGB))
    elif transformation_type == "Scaling":
        scale_x = st.sidebar.slider("Scale X", 0.1, 5.0, 1.0)
        scale_y = st.sidebar.slider("Scale Y", 0.1, 5.0, 1.0)
        transformed_img_array = cv2.resize(img_array_bgr, None, fx=scale_x, fy=scale_y, interpolation=cv2.INTER_LINEAR)
        transformed_image = Image.fromarray(cv2.cvtColor(transformed_img_array, cv2.COLOR_BGR2RGB))
    elif transformation_type == "Translation":
        tx = st.sidebar.slider("Translate X", -cols, cols, 0)
        ty = st.sidebar.slider("Translate Y", -rows, rows, 0)
        M = np.float32([[1, 0, tx], [0, 1, ty]])
        transformed_img_array = cv2.warpAffine(img_array_bgr, M, (cols, rows))
        transformed_image = Image.fromarray(cv2.cvtColor(transformed_img_array, cv2.COLOR_BGR2RGB))
    elif transformation_type == "Affine Transform":
        st.sidebar.write("Select 3 points on the image to define the transformation.")
        # This part requires user interaction on the image, which is complex in Streamlit's basic setup.
        # For simplicity, we'll use predefined points or require manual input of coordinates.
        # Let's assume manual input for now.
        st.sidebar.write("Enter coordinates for 3 source points and 3 destination points.")
        # Example placeholder for input fields - actual implementation would need more robust input handling
        # p1_src = st.sidebar.text_input("Source Point 1 (x,y)", "0,0")
        # p2_src = st.sidebar.text_input("Source Point 2 (x,y)", f"{cols-1},0")
        # p3_src = st.sidebar.text_input("Source Point 3 (x,y)", f"0,{rows-1}")
        # p1_dst = st.sidebar.text_input("Destination Point 1 (x,y)", "0,0")
        # p2_dst = st.sidebar.text_input("Destination Point 2 (x,y)", f"{cols-1},0")
        # p3_dst = st.sidebar.text_input("Destination Point 3 (x,y)", f"0,{rows-1}")

        # Using example points for demonstration
        pts1 = np.float32([[50,50],[200,50],[50,200]])
        pts2 = np.float32([[10,100],[200,50],[100,250]])

        if pts1.shape == (3, 2) and pts2.shape == (3, 2):
            M = cv2.getAffineTransform(pts1, pts2)
            transformed_img_array = cv2.warpAffine(img_array_bgr, M, (cols, rows))
            transformed_image = Image.fromarray(cv2.cvtColor(transformed_img_array, cv2.COLOR_BGR2RGB))
        else:
             st.sidebar.warning("Please enter valid coordinates for 3 points.")


    elif transformation_type == "Perspective Transform":
        st.sidebar.write("Select 4 points on the image to define the transformation.")
        # Similar to Affine Transform, requires user interaction or manual input.
        st.sidebar.write("Enter coordinates for 4 source points and 4 destination points.")
         # Using example points for demonstration
        pts1 = np.float32([[56,65],[368,52],[28,387],[389,390]])
        pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])

        if pts1.shape == (4, 2) and pts2.shape == (4, 2):
            M = cv2.getPerspectiveTransform(pts1, pts2)
            transformed_img_array = cv2.warpPerspective(img_array_bgr, M, (300, 300)) # Output size can be different
            transformed_image = Image.fromarray(cv2.cvtColor(transformed_img_array, cv2.COLOR_BGR2RGB))
        else:
             st.sidebar.warning("Please enter valid coordinates for 4 points.")


# Display images side-by-side
if image is not None:
    col1, col2 = st.columns(2)
    with col1:
        st.image(image, caption="Original Image", use_column_width=True)
    with col2:
        if transformed_image is not None:
            st.image(transformed_image, caption=f"Processed Image ({transformation_type})", use_column_width=True)
        elif color_conversion != "None" and processed_image is not None:
             st.image(processed_image, caption=f"Processed Image ({color_conversion})", use_column_width=True)
        else:
            st.write("Select a transformation or color conversion to see the processed image.")

"""## Add filtering & morphology section

### Subtask:
Add options for various filters and morphological operations (Gaussian, Mean, Median, Sobel, Laplacian, Dilation, Erosion, Opening, Closing) and integrate the OpenCV functions.

**Reasoning**:
Add a new section for Filtering & Morphology, include a selectbox for different operations, and implement the corresponding OpenCV functions with necessary input widgets for parameters like kernel size and shape.
"""

import cv2
import numpy as np
from PIL import Image

# Filtering & Morphology Section
st.sidebar.title("Filtering & Morphology")
filter_morph_type = st.sidebar.selectbox("Select Operation", ["None", "Gaussian Blur", "Mean Blur", "Median Blur", "Sobel X", "Sobel Y", "Laplacian", "Dilation", "Erosion", "Opening", "Closing"])

filtered_morph_image = None

if image is not None:
    img_array = np.array(image)
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)

    if filter_morph_type == "Gaussian Blur":
        kernel_size_gaussian = st.sidebar.slider("Kernel Size (Gaussian)", 3, 31, 9, step=2)
        filtered_morph_img_array = cv2.GaussianBlur(img_array_bgr, (kernel_size_gaussian, kernel_size_gaussian), 0)
    elif filter_morph_type == "Mean Blur":
        kernel_size_mean = st.sidebar.slider("Kernel Size (Mean)", 3, 31, 9, step=2)
        filtered_morph_img_array = cv2.blur(img_array_bgr, (kernel_size_mean, kernel_size_mean))
    elif filter_morph_type == "Median Blur":
        kernel_size_median = st.sidebar.slider("Kernel Size (Median)", 3, 31, 9, step=2)
        filtered_morph_img_array = cv2.medianBlur(img_array_bgr, kernel_size_median)
    elif filter_morph_type == "Sobel X":
        kernel_size_sobel_x = st.sidebar.slider("Kernel Size (Sobel X)", 3, 31, 3, step=2)
        sobelx = cv2.Sobel(img_array_bgr, cv2.CV_64F, 1, 0, ksize=kernel_size_sobel_x)
        abs_sobelx = cv2.convertScaleAbs(sobelx)
        filtered_morph_img_array = abs_sobelx
    elif filter_morph_type == "Sobel Y":
        kernel_size_sobel_y = st.sidebar.slider("Kernel Size (Sobel Y)", 3, 31, 3, step=2)
        sobely = cv2.Sobel(img_array_bgr, cv2.CV_64F, 0, 1, ksize=kernel_size_sobel_y)
        abs_sobely = cv2.convertScaleAbs(sobely)
        filtered_morph_img_array = abs_sobely
    elif filter_morph_type == "Laplacian":
        kernel_size_laplacian = st.sidebar.slider("Kernel Size (Laplacian)", 3, 31, 3, step=2)
        laplacian = cv2.Laplacian(img_array_bgr, cv2.CV_64F, ksize=kernel_size_laplacian)
        abs_laplacian = cv2.convertScaleAbs(laplacian)
        filtered_morph_img_array = abs_laplacian
    elif filter_morph_type in ["Dilation", "Erosion", "Opening", "Closing"]:
        kernel_size_morph = st.sidebar.slider("Kernel Size (Morphology)", 1, 15, 3)
        kernel_shape_morph = st.sidebar.selectbox("Kernel Shape", ["Rectangle", "Ellipse", "Cross"])

        if kernel_shape_morph == "Rectangle":
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size_morph, kernel_size_morph))
        elif kernel_shape_morph == "Ellipse":
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size_morph, kernel_size_morph))
        elif kernel_shape_morph == "Cross":
            kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (kernel_size_morph, kernel_size_morph))

        if filter_morph_type == "Dilation":
            filtered_morph_img_array = cv2.dilate(img_array_bgr, kernel, iterations=1)
        elif filter_morph_type == "Erosion":
            filtered_morph_img_array = cv2.erode(img_array_bgr, kernel, iterations=1)
        elif filter_morph_type == "Opening":
            filtered_morph_img_array = cv2.morphologyEx(img_array_bgr, cv2.MORPH_OPEN, kernel)
        elif filter_morph_type == "Closing":
            filtered_morph_img_array = cv2.morphologyEx(img_array_bgr, cv2.MORPH_CLOSE, kernel)
    elif filter_morph_type == "None":
        filtered_morph_img_array = img_array_bgr # Or just the original image array

    # Convert back to PIL Image for display
    if filter_morph_type in ["Sobel X", "Sobel Y", "Laplacian"] and len(filtered_morph_img_array.shape) == 3 and filtered_morph_img_array.shape[2] == 3:
         filtered_morph_image = Image.fromarray(cv2.cvtColor(filtered_morph_img_array, cv2.COLOR_BGR2RGB))
    elif len(filtered_morph_img_array.shape) == 2: # Grayscale output from some filters
         filtered_morph_image = Image.fromarray(filtered_morph_img_array, 'L')
    else:
        filtered_morph_image = Image.fromarray(cv2.cvtColor(filtered_morph_img_array, cv2.COLOR_BGR2RGB))


# Display images side-by-side
if image is not None:
    col1, col2 = st.columns(2)
    with col1:
        st.image(image, caption="Original Image", use_column_width=True)
    with col2:
        if filtered_morph_image is not None:
            st.image(filtered_morph_image, caption=f"Processed Image ({filter_morph_type})", use_column_width=True)
        elif transformed_image is not None:
             st.image(transformed_image, caption=f"Processed Image ({transformation_type})", use_column_width=True)
        elif processed_image is not None:
             st.image(processed_image, caption=f"Processed Image ({color_conversion})", use_column_width=True)
        else:
            st.write("Select an operation to see the processed image.")

"""## Add enhancement section

### Subtask:
Implement options for image enhancement techniques (Histogram Equalization, Contrast Stretching, Sharpening) and their OpenCV implementations.

**Reasoning**:
Implement the Enhancement section in the sidebar with options for Histogram Equalization, Contrast Stretching, and Sharpening, using OpenCV functions to apply these enhancements and display the result.
"""

import cv2
import numpy as np
from PIL import Image

# Enhancement Section
st.sidebar.title("Enhancement")
enhancement_type = st.sidebar.selectbox("Select Enhancement", ["None", "Histogram Equalization", "Contrast Stretching", "Sharpening"])

enhanced_image = None

if image is not None:
    img_array = np.array(image)
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)

    if enhancement_type == "Histogram Equalization":
        # Convert to grayscale if not already
        if len(img_array_bgr.shape) == 3:
            gray_img = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2GRAY)
        else:
            gray_img = img_array_bgr # Already grayscale

        equalized_img = cv2.equalizeHist(gray_img)

        # Convert back to BGR if original was color for consistent display
        if len(img_array_bgr.shape) == 3:
            enhanced_img_array = cv2.cvtColor(equalized_img, cv2.COLOR_GRAY2BGR)
        else:
            enhanced_img_array = equalized_img # Keep as grayscale

    elif enhancement_type == "Contrast Stretching":
        st.sidebar.write("Using automatic contrast stretching (min/max normalization).")
        # Using normalize for basic contrast stretching
        enhanced_img_array = cv2.normalize(img_array_bgr, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)

    elif enhancement_type == "Sharpening":
        st.sidebar.write("Applying a basic sharpening kernel.")
        # Define a sharpening kernel
        kernel_sharpening = np.array([[-1,-1,-1],
                                      [-1, 9,-1],
                                      [-1,-1,-1]])
        enhanced_img_array = cv2.filter2D(img_array_bgr, -1, kernel_sharpening)
    elif enhancement_type == "None":
        enhanced_img_array = img_array_bgr # Or just the original image array


    # Convert back to PIL Image for display
    if len(enhanced_img_array.shape) == 2: # Grayscale output
         enhanced_image = Image.fromarray(enhanced_img_array, 'L')
    else:
        enhanced_image = Image.fromarray(cv2.cvtColor(enhanced_img_array, cv2.COLOR_BGR2RGB))


# Display images side-by-side
if image is not None:
    col1, col2 = st.columns(2)
    with col1:
        st.image(image, caption="Original Image", use_column_width=True)
    with col2:
        if enhanced_image is not None:
            st.image(enhanced_image, caption=f"Processed Image ({enhancement_type})", use_column_width=True)
        elif filtered_morph_image is not None:
             st.image(filtered_morph_image, caption=f"Processed Image ({filter_morph_type})", use_column_width=True)
        elif transformed_image is not None:
             st.image(transformed_image, caption=f"Processed Image ({transformation_type})", use_column_width=True)
        elif processed_image is not None:
             st.image(processed_image, caption=f"Processed Image ({color_conversion})", use_column_width=True)
        else:
            st.write("Select an operation to see the processed image.")

"""## Add edge detection section

### Subtask:
Include options for edge detection algorithms (Sobel, Canny, Laplacian) and integrate the OpenCV code.

**Reasoning**:
Add the "Edge Detection" section to the sidebar, create a selectbox for different edge detection methods, and implement the OpenCV code for Sobel, Canny, and Laplacian edge detection, including parameter inputs and displaying the resulting image.
"""

import cv2
import numpy as np
from PIL import Image

# Edge Detection Section
st.sidebar.title("Edge Detection")
edge_detection_type = st.sidebar.selectbox("Select Edge Detection", ["None", "Sobel", "Canny", "Laplacian"])

edge_detected_image = None

if image is not None:
    img_array = np.array(image)
    # Convert to grayscale for edge detection if it's a color image
    if len(img_array.shape) == 3:
        gray_img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
    else:
        gray_img_array = img_array # Already grayscale

    if edge_detection_type == "Sobel":
        st.sidebar.write("Sobel Edge Detection Parameters:")
        sobel_x = st.sidebar.checkbox("Detect X edges", value=True)
        sobel_y = st.sidebar.checkbox("Detect Y edges", value=True)
        kernel_size_sobel = st.sidebar.slider("Kernel Size (Sobel)", 3, 31, 3, step=2)

        if sobel_x and sobel_y:
            sobelx = cv2.Sobel(gray_img_array, cv2.CV_64F, 1, 0, ksize=kernel_size_sobel)
            sobely = cv2.Sobel(gray_img_array, cv2.CV_64F, 0, 1, ksize=kernel_size_sobel)
            sobel_combined = np.sqrt(sobelx**2 + sobely**2)
            edge_detected_img_array = cv2.convertScaleAbs(sobel_combined)
        elif sobel_x:
            sobelx = cv2.Sobel(gray_img_array, cv2.CV_64F, 1, 0, ksize=kernel_size_sobel)
            edge_detected_img_array = cv2.convertScaleAbs(sobelx)
        elif sobel_y:
            sobely = cv2.Sobel(gray_img_array, cv2.CV_64F, 0, 1, ksize=kernel_size_sobel)
            edge_detected_img_array = cv2.convertScaleAbs(sobely)
        else:
             edge_detected_img_array = gray_img_array # No detection selected

    elif edge_detection_type == "Canny":
        st.sidebar.write("Canny Edge Detection Parameters:")
        threshold1 = st.sidebar.slider("Threshold 1 (Canny)", 0, 255, 100)
        threshold2 = st.sidebar.slider("Threshold 2 (Canny)", 0, 255, 200)
        aperture_size = st.sidebar.slider("Aperture Size (Canny)", 3, 7, 3, step=2)
        L2gradient = st.sidebar.checkbox("Use L2 gradient", value=False)

        edge_detected_img_array = cv2.Canny(gray_img_array, threshold1, threshold2, apertureSize=aperture_size, L2gradient=L2gradient)

    elif edge_detection_type == "Laplacian":
        st.sidebar.write("Laplacian Edge Detection Parameters:")
        kernel_size_laplacian = st.sidebar.slider("Kernel Size (Laplacian)", 1, 31, 3, step=2)

        laplacian = cv2.Laplacian(gray_img_array, cv2.CV_64F, ksize=kernel_size_laplacian)
        edge_detected_img_array = cv2.convertScaleAbs(laplacian)
    elif edge_detection_type == "None":
        # If no edge detection is selected, use the grayscale image for consistency in the pipeline
        edge_detected_img_array = gray_img_array


    # Convert the processed NumPy array (grayscale) back to a PIL Image
    edge_detected_image = Image.fromarray(edge_detected_img_array, 'L') # 'L' mode for grayscale

# Display images side-by-side, prioritizing edge detection
if image is not None:
    col1, col2 = st.columns(2)
    with col1:
        st.image(image, caption="Original Image", use_column_width=True)
    with col2:
        if edge_detected_image is not None and edge_detection_type != "None":
            st.image(edge_detected_image, caption=f"Processed Image ({edge_detection_type})", use_column_width=True)
        elif enhanced_image is not None and enhancement_type != "None":
            st.image(enhanced_image, caption=f"Processed Image ({enhancement_type})", use_column_width=True)
        elif filtered_morph_image is not None and filter_morph_type != "None":
             st.image(filtered_morph_image, caption=f"Processed Image ({filter_morph_type})", use_column_width=True)
        elif transformed_image is not None and transformation_type != "None":
             st.image(transformed_image, caption=f"Processed Image ({transformation_type})", use_column_width=True)
        elif processed_image is not None and color_conversion != "None":
             st.image(processed_image, caption=f"Processed Image ({color_conversion})", use_column_width=True)
        else:
            st.write("Select an operation to see the processed image.")

"""## Add compression section

### Subtask:
Add options to save the processed image in different formats (JPG, PNG, BMP) and potentially display file size and quality comparisons.

**Reasoning**:
The subtask is to add saving functionality with format and quality options. This requires modifying the "File" section to include a "Save As" option, adding widgets for format and quality selection, and implementing the save logic using Pillow. This can be done in a single code block.
"""

import streamlit as st
from PIL import Image
import numpy as np
import cv2
import io
import os

st.set_page_config(layout="wide")

st.title("Image Processing Application")

# Menu Bar
st.sidebar.title("Menu")

# File operations
file_operation = st.sidebar.selectbox("File", ["", "Open", "Save As", "Exit"])

# Initialize variables for processed images from previous steps
# These should ideally be managed using Streamlit's session state in a real app
# For this sequential execution, we'll re-initialize or rely on the last state if possible
# However, in a stateless environment like this, we need to ensure the processed image is available.
# Let's assume 'processed_image' holds the result of the last applied operation.
# A more robust solution would pass the image through the pipeline.
# For this subtask, we will save the *last* processed image that was generated
# by any of the previous sections (color_conversion, transformation, filtering, enhancement, edge_detection).
# We need a variable to hold the currently displayed processed image.

# Placeholder for the currently displayed processed image
current_processed_image = None

# Re-run previous sections' logic to get the processed image based on current selections
# This is a simplified approach for sequential execution. In a real Streamlit app,
# selections would trigger re-runs and update session state.

# --- Previous sections' logic (simplified to determine current_processed_image) ---
# Assuming image, color_conversion, transformation_type, filter_morph_type, enhancement_type, edge_detection_type
# are available from the execution history and retain their last selected values.

if image is not None:
    img_array = np.array(image)
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
    gray_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2GRAY) # Ensure grayscale is available if needed

    # Determine which processed image to save based on the last active operation
    # Prioritize the most recent operations
    if 'edge_detected_img_array' in locals() and edge_detection_type != "None":
        current_processed_image = Image.fromarray(edge_detected_img_array, 'L') if len(edge_detected_img_array.shape) == 2 else Image.fromarray(cv2.cvtColor(edge_detected_img_array, cv2.COLOR_BGR2RGB))
    elif 'enhanced_img_array' in locals() and enhancement_type != "None":
         current_processed_image = Image.fromarray(enhanced_img_array, 'L') if len(enhanced_img_array.shape) == 2 else Image.fromarray(cv2.cvtColor(enhanced_img_array, cv2.COLOR_BGR2RGB))
    elif 'filtered_morph_img_array' in locals() and filter_morph_type != "None":
         current_processed_image = Image.fromarray(filtered_morph_img_array, 'L') if len(filtered_morph_img_array.shape) == 2 else Image.fromarray(cv2.cvtColor(filtered_morph_img_array, cv2.COLOR_BGR2RGB))
    elif 'transformed_img_array' in locals() and transformation_type != "None":
         current_processed_image = Image.fromarray(cv2.cvtColor(transformed_img_array, cv2.COLOR_BGR2RGB))
    elif 'processed_image_array' in locals() and color_conversion != "None":
         current_processed_image = Image.fromarray(processed_image_array, 'L') if len(processed_image_array.shape) == 2 else Image.fromarray(processed_image_array)
    else:
        current_processed_image = image # Default to original if no processing applied


# --- End of previous sections' logic ---

# File operations handling
if file_operation == "Open":
    uploaded_file = st.sidebar.file_uploader("Choose an image...", type=["jpg", "jpeg", "png", "bmp", "tiff"])
    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        # Store the original image for potential later use or display
        st.session_state['original_image'] = image
        st.image(image, caption="Uploaded Image", use_column_width=True)
        current_processed_image = image # When opening, the processed image is the original
elif file_operation == "Save As":
    if current_processed_image is not None:
        st.sidebar.subheader("Save Options")
        output_format = st.sidebar.selectbox("Select output format", ["PNG", "JPEG", "BMP"])

        if output_format == "JPEG":
            jpeg_quality = st.sidebar.slider("JPEG Quality", 0, 100, 95)
            # Use BytesIO to save to memory first, then allow download
            img_byte_arr = io.BytesIO()
            current_processed_image.save(img_byte_arr, format='JPEG', quality=jpeg_quality)
            img_byte_arr = img_byte_arr.getvalue()
            file_extension = "jpg"
            mime_type = "image/jpeg"
        elif output_format == "PNG":
             img_byte_arr = io.BytesIO()
             current_processed_image.save(img_byte_arr, format='PNG')
             img_byte_arr = img_byte_arr.getvalue()
             file_extension = "png"
             mime_type = "image/png"
        elif output_format == "BMP":
             img_byte_arr = io.BytesIO()
             current_processed_image.save(img_byte_arr, format='BMP')
             img_byte_arr = img_byte_arr.getvalue()
             file_extension = "bmp"
             mime_type = "image/bmp"

        # Provide a download button
        st.sidebar.download_button(
            label=f"Download Image as {output_format}",
            data=img_byte_arr,
            file_name=f"processed_image.{file_extension}",
            mime=mime_type
        )

        # Optionally display file size
        st.sidebar.write(f"File size: {len(img_byte_arr) / 1024:.2f} KB")

    else:
        st.sidebar.warning("No image to save. Please open an image first.")

elif file_operation == "Exit":
    st.sidebar.write("Exit functionality will be implemented later.")


# Main content area (for displaying images and results)
st.subheader("Image Display Area")

# Display images side-by-side, showing the original and the *currently processed* image
if 'original_image' in st.session_state:
    col1, col2 = st.columns(2)
    with col1:
        st.image(st.session_state['original_image'], caption="Original Image", use_column_width=True)
    with col2:
        if current_processed_image is not None:
            st.image(current_processed_image, caption="Processed Image", use_column_width=True)
        else:
            st.write("Apply an operation to see the processed image.")

# --- Previous sections' sidebars (kept for context, assuming they are executed) ---
# Image Info Section
st.sidebar.title("Image Info")
if 'original_image' in st.session_state:
    img_info = st.session_state['original_image']
    st.sidebar.write(f"Resolution: {img_info.width} x {img_info.height}")
    st.sidebar.write(f"Shape: {np.array(img_info).shape}")
    if img_info.info and 'dpi' in img_info.info:
        st.sidebar.write(f"DPI: {img_info.info['dpi']}")
    else:
        st.sidebar.write("DPI: N/A")
    st.sidebar.write(f"Format: {img_info.format}")
    st.sidebar.write(f"Channels: {len(img_info.getbands())}")
else:
    st.sidebar.write("No image loaded yet.")

# Color Conversions Section
st.sidebar.title("Color Conversions")
# This selectbox needs to be re-evaluated in the context of the full app state
# color_conversion = st.sidebar.selectbox("Select Conversion", ["None", "RGB to BGR", "BGR to RGB", "RGB to HSV", "HSV to RGB", "RGB to YCbCr", "YCbCr to RGB", "RGB to Grayscale"])

# Transformations Section
st.sidebar.title("Transformations")
# transformation_type = st.sidebar.selectbox("Select Transformation", ["None", "Rotation", "Scaling", "Translation", "Affine Transform", "Perspective Transform"])

# Filtering & Morphology Section
st.sidebar.title("Filtering & Morphology")
# filter_morph_type = st.sidebar.selectbox("Select Operation", ["None", "Gaussian Blur", "Mean Blur", "Median Blur", "Sobel", "Laplacian", "Dilation", "Erosion", "Opening", "Closing"])

# Enhancement Section
st.sidebar.title("Enhancement")
# enhancement_type = st.sidebar.selectbox("Select Enhancement", ["None", "Histogram Equalization", "Contrast Stretching", "Sharpening"])

# Edge Detection Section
st.sidebar.title("Edge Detection")
# edge_detection_type = st.sidebar.selectbox("Select Edge Detection", ["None", "Sobel", "Canny", "Laplacian"])

# Note: In a real Streamlit app, the processing logic would be triggered by
# the selectbox selections and update a state variable holding the processed image.
# The file saving would then operate on this state variable.
# The current structure is a bit simplified for sequential execution in this notebook environment.

"""## Refine gui and display

### Subtask:
Organize the sidebar with clear sections and implement the display of the original and processed images side-by-side in the main content area.

**Reasoning**:
The subtask is to organize the sidebar with clear sections and implement the display of original and processed images side-by-side. The existing code already includes most of the sidebar sections and the side-by-side display logic. I need to review the existing code to ensure all the required sections are present and correctly titled, and the side-by-side display is implemented correctly and uses the last processed image. I will consolidate the sidebar section titles and the image display logic.
"""

import streamlit as st
from PIL import Image
import numpy as np
import cv2
import io

st.set_page_config(layout="wide")

st.title("Image Processing Application")

# Use Streamlit's session state to manage the original and processed images
if 'original_image' not in st.session_state:
    st.session_state['original_image'] = None
if 'processed_image' not in st.session_state:
    st.session_state['processed_image'] = None
if 'processed_image_caption' not in st.session_state:
     st.session_state['processed_image_caption'] = "Processed Image"


# Menu Bar
st.sidebar.title("Menu")

# File operations
file_operation = st.sidebar.selectbox("File", ["", "Open", "Save As", "Exit"], key='file_op')

if file_operation == "Open":
    uploaded_file = st.sidebar.file_uploader("Choose an image...", type=["jpg", "jpeg", "png", "bmp", "tiff"], key='file_uploader')
    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        st.session_state['original_image'] = image
        st.session_state['processed_image'] = image # Initially, processed is the same as original
        st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"
elif file_operation == "Save As":
    if st.session_state['processed_image'] is not None:
        st.sidebar.subheader("Save Options")
        output_format = st.sidebar.selectbox("Select output format", ["PNG", "JPEG", "BMP"], key='save_format')

        img_byte_arr = io.BytesIO()
        file_extension = "png"
        mime_type = "image/png"

        if output_format == "JPEG":
            jpeg_quality = st.sidebar.slider("JPEG Quality", 0, 100, 95, key='jpeg_quality')
            st.session_state['processed_image'].save(img_byte_arr, format='JPEG', quality=jpeg_quality)
            file_extension = "jpg"
            mime_type = "image/jpeg"
        elif output_format == "PNG":
             st.session_state['processed_image'].save(img_byte_arr, format='PNG')
             file_extension = "png"
             mime_type = "image/png"
        elif output_format == "BMP":
             st.session_state['processed_image'].save(img_byte_arr, format='BMP')
             file_extension = "bmp"
             mime_type = "image/bmp"

        st.sidebar.download_button(
            label=f"Download Image as {output_format}",
            data=img_byte_arr.getvalue(),
            file_name=f"processed_image.{file_extension}",
            mime=mime_type,
            key='download_button'
        )
        st.sidebar.write(f"File size: {len(img_byte_arr.getvalue()) / 1024:.2f} KB")

    else:
        st.sidebar.warning("No image to save. Please open an image first.")

elif file_operation == "Exit":
    st.stop()


# Sidebar Sections (Organized)
st.sidebar.title("Image Info")
if st.session_state['original_image'] is not None:
    img_info = st.session_state['original_image']
    st.sidebar.write(f"Resolution: {img_info.width} x {img_info.height}")
    st.sidebar.write(f"Shape: {np.array(img_info).shape}")
    if img_info.info and 'dpi' in img_info.info:
        st.sidebar.write(f"DPI: {img_info.info['dpi']}")
    else:
        st.sidebar.write("DPI: N/A")
    st.sidebar.write(f"Format: {img_info.format}")
    st.sidebar.write(f"Channels: {len(img_info.getbands())}")
else:
    st.sidebar.write("No image loaded yet.")


st.sidebar.title("Color Conversions")
color_conversion = st.sidebar.selectbox("Select Conversion", ["None", "RGB to BGR", "BGR to RGB", "RGB to HSV", "HSV to RGB", "RGB to YCbCr", "YCbCr to RGB", "RGB to Grayscale"], key='color_conversion')

if st.session_state['original_image'] is not None and color_conversion != "None":
    img_array = np.array(st.session_state['original_image'])
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)

    processed_img_array = None

    if color_conversion == "RGB to BGR":
        processed_img_array = img_array_bgr # Already in BGR for processing
    elif color_conversion == "BGR to RGB":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2RGB)
    elif color_conversion == "RGB to HSV":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2HSV)
    elif color_conversion == "HSV to RGB":
        img_array_hsv = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2HSV)
        processed_img_array = cv2.cvtColor(img_array_hsv, cv2.COLOR_HSV2RGB)
    elif color_conversion == "RGB to YCbCr":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2YCR_CB)
    elif color_conversion == "YCbCr to RGB":
        img_array_ycbcr = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2YCR_CB)
        processed_img_array = cv2.cvtColor(img_array_ycbcr, cv2.COLOR_YCR_CB2RGB)
    elif color_conversion == "RGB to Grayscale":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2GRAY)

    if processed_img_array is not None:
        if len(processed_img_array.shape) == 2:
             st.session_state['processed_image'] = Image.fromarray(processed_img_array, 'L')
        else:
            # Assuming color conversions result in BGR, convert to RGB for PIL display
             st.session_state['processed_image'] = Image.fromarray(cv2.cvtColor(processed_img_array, cv2.COLOR_BGR2RGB))
        st.session_state['processed_image_caption'] = f"Processed Image ({color_conversion})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"


st.sidebar.title("Transformations")
transformation_type = st.sidebar.selectbox("Select Transformation", ["None", "Rotation", "Scaling", "Translation", "Affine Transform", "Perspective Transform"], key='transformation_type')

if st.session_state['original_image'] is not None and transformation_type != "None":
    img_array = np.array(st.session_state['original_image'])
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
    rows, cols, _ = img_array_bgr.shape
    transformed_img_array = None

    if transformation_type == "Rotation":
        angle = st.sidebar.slider("Angle (degrees)", -180, 180, 0, key='rot_angle')
        M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)
        transformed_img_array = cv2.warpAffine(img_array_bgr, M, (cols, rows))
    elif transformation_type == "Scaling":
        scale_x = st.sidebar.slider("Scale X", 0.1, 5.0, 1.0, key='scale_x')
        scale_y = st.sidebar.slider("Scale Y", 0.1, 5.0, 1.0, key='scale_y')
        transformed_img_array = cv2.resize(img_array_bgr, None, fx=scale_x, fy=scale_y, interpolation=cv2.INTER_LINEAR)
    elif transformation_type == "Translation":
        tx = st.sidebar.slider("Translate X", -cols, cols, 0, key='trans_x')
        ty = st.sidebar.slider("Translate Y", -rows, rows, 0, key='trans_y')
        M = np.float32([[1, 0, tx], [0, 1, ty]])
        transformed_img_array = cv2.warpAffine(img_array_bgr, M, (cols, rows))
    elif transformation_type == "Affine Transform":
        st.sidebar.write("Using example points for demonstration.")
        pts1 = np.float32([[50,50],[200,50],[50,200]])
        pts2 = np.float32([[10,100],[200,50],[100,250]])
        if pts1.shape == (3, 2) and pts2.shape == (3, 2):
            M = cv2.getAffineTransform(pts1, pts2)
            transformed_img_array = cv2.warpAffine(img_array_bgr, M, (cols, rows))
        else:
             st.sidebar.warning("Invalid coordinates for Affine Transform example.")
             transformed_img_array = img_array_bgr
    elif transformation_type == "Perspective Transform":
        st.sidebar.write("Using example points for demonstration.")
        pts1 = np.float32([[56,65],[368,52],[28,387],[389,390]])
        pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])
        if pts1.shape == (4, 2) and pts2.shape == (4, 2):
            M = cv2.getPerspectiveTransform(pts1, pts2)
            transformed_img_array = cv2.warpPerspective(img_array_bgr, M, (300, 300)) # Output size can be different
        else:
            st.sidebar.warning("Invalid coordinates for Perspective Transform example.")
            transformed_img_array = img_array_bgr

    if transformed_img_array is not None:
         st.session_state['processed_image'] = Image.fromarray(cv2.cvtColor(transformed_img_array, cv2.COLOR_BGR2RGB))
         st.session_state['processed_image_caption'] = f"Processed Image ({transformation_type})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"

st.sidebar.title("Filtering & Morphology")
filter_morph_type = st.sidebar.selectbox("Select Operation", ["None", "Gaussian Blur", "Mean Blur", "Median Blur", "Sobel X", "Sobel Y", "Laplacian", "Dilation", "Erosion", "Opening", "Closing"], key='filter_morph_type')

if st.session_state['original_image'] is not None and filter_morph_type != "None":
    img_array = np.array(st.session_state['original_image'])
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
    filtered_morph_img_array = None

    if filter_morph_type == "Gaussian Blur":
        kernel_size_gaussian = st.sidebar.slider("Kernel Size (Gaussian)", 3, 31, 9, step=2, key='gauss_ksize')
        filtered_morph_img_array = cv2.GaussianBlur(img_array_bgr, (kernel_size_gaussian, kernel_size_gaussian), 0)
    elif filter_morph_type == "Mean Blur":
        kernel_size_mean = st.sidebar.slider("Kernel Size (Mean)", 3, 31, 9, step=2, key='mean_ksize')
        filtered_morph_img_array = cv2.blur(img_array_bgr, (kernel_size_mean, kernel_size_mean))
    elif filter_morph_type == "Median Blur":
        kernel_size_median = st.sidebar.slider("Kernel Size (Median)", 3, 31, 9, step=2, key='median_ksize')
        filtered_morph_img_array = cv2.medianBlur(img_array_bgr, kernel_size_median)
    elif filter_morph_type == "Sobel X":
        kernel_size_sobel_x = st.sidebar.slider("Kernel Size (Sobel X)", 3, 31, 3, step=2, key='sobelx_ksize_fm')
        sobelx = cv2.Sobel(img_array_bgr, cv2.CV_64F, 1, 0, ksize=kernel_size_sobel_x)
        filtered_morph_img_array = cv2.convertScaleAbs(sobelx)
    elif filter_morph_type == "Sobel Y":
        kernel_size_sobel_y = st.sidebar.slider("Kernel Size (Sobel Y)", 3, 31, 3, step=2, key='sobely_ksize_fm')
        sobely = cv2.Sobel(img_array_bgr, cv2.CV_64F, 0, 1, ksize=kernel_size_sobel_y)
        filtered_morph_img_array = cv2.convertScaleAbs(sobely)
    elif filter_morph_type == "Laplacian":
        kernel_size_laplacian = st.sidebar.slider("Kernel Size (Laplacian)", 3, 31, 3, step=2, key='laplacian_ksize_fm')
        laplacian = cv2.Laplacian(img_array_bgr, cv2.CV_64F, ksize=kernel_size_laplacian)
        filtered_morph_img_array = cv2.convertScaleAbs(laplacian)
    elif filter_morph_type in ["Dilation", "Erosion", "Opening", "Closing"]:
        kernel_size_morph = st.sidebar.slider("Kernel Size (Morphology)", 1, 15, 3, key='morph_ksize')
        kernel_shape_morph = st.sidebar.selectbox("Kernel Shape", ["Rectangle", "Ellipse", "Cross"], key='morph_shape')

        if kernel_shape_morph == "Rectangle":
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size_morph, kernel_size_morph))
        elif kernel_shape_morph == "Ellipse":
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size_morph, kernel_size_morph))
        elif kernel_shape_morph == "Cross":
            kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (kernel_size_morph, kernel_size_morph))

        if filter_morph_type == "Dilation":
            filtered_morph_img_array = cv2.dilate(img_array_bgr, kernel, iterations=1)
        elif filter_morph_type == "Erosion":
            filtered_morph_img_array = cv2.erode(img_array_bgr, kernel, iterations=1)
        elif filter_morph_type == "Opening":
            filtered_morph_img_array = cv2.morphologyEx(img_array_bgr, cv2.MORPH_OPEN, kernel)
        elif filter_morph_type == "Closing":
            filtered_morph_img_array = cv2.morphologyEx(img_array_bgr, cv2.MORPH_CLOSE, kernel)

    if filtered_morph_img_array is not None:
        if len(filtered_morph_img_array.shape) == 2:
             st.session_state['processed_image'] = Image.fromarray(filtered_morph_img_array, 'L')
        else:
            st.session_state['processed_image'] = Image.fromarray(cv2.cvtColor(filtered_morph_img_array, cv2.COLOR_BGR2RGB))
        st.session_state['processed_image_caption'] = f"Processed Image ({filter_morph_type})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"

st.sidebar.title("Enhancement")
enhancement_type = st.sidebar.selectbox("Select Enhancement", ["None", "Histogram Equalization", "Contrast Stretching", "Sharpening"], key='enhancement_type')

if st.session_state['original_image'] is not None and enhancement_type != "None":
    img_array = np.array(st.session_state['original_image'])
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
    enhanced_img_array = None

    if enhancement_type == "Histogram Equalization":
        if len(img_array_bgr.shape) == 3:
            gray_img = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2GRAY)
        else:
            gray_img = img_array_bgr
        equalized_img = cv2.equalizeHist(gray_img)
        if len(img_array_bgr.shape) == 3:
            enhanced_img_array = cv2.cvtColor(equalized_img, cv2.COLOR_GRAY2BGR)
        else:
            enhanced_img_array = equalized_img
    elif enhancement_type == "Contrast Stretching":
        enhanced_img_array = cv2.normalize(img_array_bgr, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)
    elif enhancement_type == "Sharpening":
        kernel_sharpening = np.array([[-1,-1,-1], [-1, 9,-1], [-1,-1,-1]])
        enhanced_img_array = cv2.filter2D(img_array_bgr, -1, kernel_sharpening)

    if enhanced_img_array is not None:
        if len(enhanced_img_array.shape) == 2:
             st.session_state['processed_image'] = Image.fromarray(enhanced_img_array, 'L')
        else:
            st.session_state['processed_image'] = Image.fromarray(cv2.cvtColor(enhanced_img_array, cv2.COLOR_BGR2RGB))
        st.session_state['processed_image_caption'] = f"Processed Image ({enhancement_type})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"


st.sidebar.title("Edge Detection")
edge_detection_type = st.sidebar.selectbox("Select Edge Detection", ["None", "Sobel", "Canny", "Laplacian"], key='edge_detection_type')

if st.session_state['original_image'] is not None and edge_detection_type != "None":
    img_array = np.array(st.session_state['original_image'])
    if len(img_array.shape) == 3:
        gray_img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
    else:
        gray_img_array = img_array

    edge_detected_img_array = None

    if edge_detection_type == "Sobel":
        sobel_x = st.sidebar.checkbox("Detect X edges", value=True, key='sobel_x_edge')
        sobel_y = st.sidebar.checkbox("Detect Y edges", value=True, key='sobel_y_edge')
        kernel_size_sobel = st.sidebar.slider("Kernel Size (Sobel)", 3, 31, 3, step=2, key='sobel_ksize_edge')
        if sobel_x and sobel_y:
            sobelx = cv2.Sobel(gray_img_array, cv2.CV_64F, 1, 0, ksize=kernel_size_sobel)
            sobely = cv2.Sobel(gray_img_array, cv2.CV_64F, 0, 1, ksize=kernel_size_sobel)
            sobel_combined = np.sqrt(sobelx**2 + sobely**2)
            edge_detected_img_array = cv2.convertScaleAbs(sobel_combined)
        elif sobel_x:
            sobelx = cv2.Sobel(gray_img_array, cv2.CV_64F, 1, 0, ksize=kernel_size_sobel)
            edge_detected_img_array = cv2.convertScaleAbs(sobelx)
        elif sobel_y:
            sobely = cv2.Sobel(gray_img_array, cv2.CV_64F, 0, 1, ksize=kernel_size_sobel)
            edge_detected_img_array = cv2.convertScaleAbs(sobely)
        else:
             edge_detected_img_array = gray_img_array
    elif edge_detection_type == "Canny":
        threshold1 = st.sidebar.slider("Threshold 1 (Canny)", 0, 255, 100, key='canny_thresh1')
        threshold2 = st.sidebar.slider("Threshold 2 (Canny)", 0, 255, 200, key='canny_thresh2')
        aperture_size = st.sidebar.slider("Aperture Size (Canny)", 3, 7, 3, step=2, key='canny_aperture')
        L2gradient = st.sidebar.checkbox("Use L2 gradient", value=False, key='canny_l2')
        edge_detected_img_array = cv2.Canny(gray_img_array, threshold1, threshold2, apertureSize=aperture_size, L2gradient=L2gradient)
    elif edge_detection_type == "Laplacian":
        kernel_size_laplacian = st.sidebar.slider("Kernel Size (Laplacian)", 1, 31, 3, step=2, key='laplacian_ksize_edge')
        laplacian = cv2.Laplacian(gray_img_array, cv2.CV_64F, ksize=kernel_size_laplacian)
        edge_detected_img_array = cv2.convertScaleAbs(laplacian)

    if edge_detected_img_array is not None:
        st.session_state['processed_image'] = Image.fromarray(edge_detected_img_array, 'L')
        st.session_state['processed_image_caption'] = f"Processed Image ({edge_detection_type})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"


# Main content area (for displaying images and results)
st.subheader("Image Display Area")

if st.session_state['original_image'] is not None:
    col1, col2 = st.columns(2)
    with col1:
        st.image(st.session_state['original_image'], caption="Original Image", use_column_width=True)
    with col2:
        if st.session_state['processed_image'] is not None:
            st.image(st.session_state['processed_image'], caption=st.session_state['processed_image_caption'], use_column_width=True)
        else:
            st.write("Apply an operation to see the processed image.")

# Status Bar
st.subheader("Status")
if st.session_state['original_image'] is not None:
    img_info = st.session_state['processed_image'] if st.session_state['processed_image'] is not None else st.session_state['original_image']
    img_array = np.array(img_info)
    height, width = img_array.shape[:2]
    channels = img_array.shape[2] if len(img_array.shape) == 3 else 1
    dpi = img_info.info.get('dpi', 'N/A')
    format = img_info.format

    # To get file size, we need to save the image to a BytesIO object first
    img_byte_arr = io.BytesIO()
    try:
        img_info.save(img_byte_arr, format=format if format else 'PNG') # Use PNG if format is None
        file_size = len(img_byte_arr.getvalue()) / 1024 # size in KB
        st.write(f"Dimensions: {width} x {height} x {channels} | DPI/PPI: {dpi} | Format: {format if format else 'N/A'} | File Size: {file_size:.2f} KB")
    except Exception as e:
        st.write(f"Dimensions: {width} x {height} x {channels} | DPI/PPI: {dpi} | Format: {format if format else 'N/A'} | File Size: Could not determine ({e})")
else:
    st.write("Load an image to see status information.")

import streamlit as st
from PIL import Image
import numpy as np
import cv2
import io

st.set_page_config(layout="wide")

st.title("Image Processing Application")

# Use Streamlit's session state to manage the original and processed images
if 'original_image' not in st.session_state:
    st.session_state['original_image'] = None
if 'processed_image' not in st.session_state:
    st.session_state['processed_image'] = None
if 'processed_image_caption' not in st.session_state:
     st.session_state['processed_image_caption'] = "Processed Image"


# Menu Bar
st.sidebar.title("Menu")

# File operations
file_operation = st.sidebar.selectbox("File", ["", "Open", "Save As", "Exit"], key='file_op')

if file_operation == "Open":
    uploaded_file = st.sidebar.file_uploader("Choose an image...", type=["jpg", "jpeg", "png", "bmp", "tiff"], key='file_uploader')
    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        st.session_state['original_image'] = image
        st.session_state['processed_image'] = image # Initially, processed is the same as original
        st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"
elif file_operation == "Save As":
    if st.session_state['processed_image'] is not None:
        st.sidebar.subheader("Save Options")
        output_format = st.sidebar.selectbox("Select output format", ["PNG", "JPEG", "BMP"], key='save_format')

        img_byte_arr = io.BytesIO()
        file_extension = "png"
        mime_type = "image/png"

        if output_format == "JPEG":
            jpeg_quality = st.sidebar.slider("JPEG Quality", 0, 100, 95, key='jpeg_quality')
            st.session_state['processed_image'].save(img_byte_arr, format='JPEG', quality=jpeg_quality)
            file_extension = "jpg"
            mime_type = "image/jpeg"
        elif output_format == "PNG":
             st.session_state['processed_image'].save(img_byte_arr, format='PNG')
             file_extension = "png"
             mime_type = "image/png"
        elif output_format == "BMP":
             st.session_state['processed_image'].save(img_byte_arr, format='BMP')
             file_extension = "bmp"
             mime_type = "image/bmp"

        st.sidebar.download_button(
            label=f"Download Image as {output_format}",
            data=img_byte_arr.getvalue(),
            file_name=f"processed_image.{file_extension}",
            mime=mime_type,
            key='download_button'
        )
        st.sidebar.write(f"File size: {len(img_byte_arr.getvalue()) / 1024:.2f} KB")

    else:
        st.sidebar.warning("No image to save. Please open an image first.")

elif file_operation == "Exit":
    st.stop()


# Sidebar Sections (Organized)
st.sidebar.title("Image Info")
if st.session_state['original_image'] is not None:
    img_info = st.session_state['original_image']
    st.sidebar.write(f"Resolution: {img_info.width} x {img_info.height}")
    st.sidebar.write(f"Shape: {np.array(img_info).shape}")
    if img_info.info and 'dpi' in img_info.info:
        st.sidebar.write(f"DPI: {img_info.info['dpi']}")
    else:
        st.sidebar.write("DPI: N/A")
    st.sidebar.write(f"Format: {img_info.format}")
    st.sidebar.write(f"Channels: {len(img_info.getbands())}")
else:
    st.sidebar.write("No image loaded yet.")


st.sidebar.title("Color Conversions")
color_conversion = st.sidebar.selectbox("Select Conversion", ["None", "RGB to BGR", "BGR to RGB", "RGB to HSV", "HSV to RGB", "RGB to YCbCr", "YCbCr to RGB", "RGB to Grayscale"], key='color_conversion')

if st.session_state['original_image'] is not None and color_conversion != "None":
    img_array = np.array(st.session_state['original_image'])
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)

    processed_img_array = None

    if color_conversion == "RGB to BGR":
        processed_img_array = img_array_bgr # Already in BGR for processing
    elif color_conversion == "BGR to RGB":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2RGB)
    elif color_conversion == "RGB to HSV":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2HSV)
    elif color_conversion == "HSV to RGB":
        img_array_hsv = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2HSV)
        processed_img_array = cv2.cvtColor(img_array_hsv, cv2.COLOR_HSV2RGB)
    elif color_conversion == "RGB to YCbCr":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2YCR_CB)
    elif color_conversion == "YCbCr to RGB":
        img_array_ycbcr = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2YCR_CB)
        processed_img_array = cv2.cvtColor(img_array_ycbcr, cv2.COLOR_YCR_CB2RGB)
    elif color_conversion == "RGB to Grayscale":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2GRAY)

    if processed_img_array is not None:
        if len(processed_img_array.shape) == 2:
             st.session_state['processed_image'] = Image.fromarray(processed_img_array, 'L')
        else:
            # Assuming color conversions result in BGR, convert to RGB for PIL display
             st.session_state['processed_image'] = Image.fromarray(cv2.cvtColor(processed_img_array, cv2.COLOR_BGR2RGB))
        st.session_state['processed_image_caption'] = f"Processed Image ({color_conversion})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"


st.sidebar.title("Transformations")
transformation_type = st.sidebar.selectbox("Select Transformation", ["None", "Rotation", "Scaling", "Translation", "Affine Transform", "Perspective Transform"], key='transformation_type')

if st.session_state['original_image'] is not None and transformation_type != "None":
    img_array = np.array(st.session_state['original_image'])
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
    rows, cols, _ = img_array_bgr.shape
    transformed_img_array = None

    if transformation_type == "Rotation":
        angle = st.sidebar.slider("Angle (degrees)", -180, 180, 0, key='rot_angle')
        M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)
        transformed_img_array = cv2.warpAffine(img_array_bgr, M, (cols, rows))
    elif transformation_type == "Scaling":
        scale_x = st.sidebar.slider("Scale X", 0.1, 5.0, 1.0, key='scale_x')
        scale_y = st.sidebar.slider("Scale Y", 0.1, 5.0, 1.0, key='scale_y')
        transformed_img_array = cv2.resize(img_array_bgr, None, fx=scale_x, fy=scale_y, interpolation=cv2.INTER_LINEAR)
    elif transformation_type == "Translation":
        tx = st.sidebar.slider("Translate X", -cols, cols, 0, key='trans_x')
        ty = st.sidebar.slider("Translate Y", -rows, rows, 0, key='trans_y')
        M = np.float32([[1, 0, tx], [0, 1, ty]])
        transformed_img_array = cv2.warpAffine(img_array_bgr, M, (cols, rows))
    elif transformation_type == "Affine Transform":
        st.sidebar.write("Using example points for demonstration.")
        pts1 = np.float32([[50,50],[200,50],[50,200]])
        pts2 = np.float32([[10,100],[200,50],[100,250]])
        if pts1.shape == (3, 2) and pts2.shape == (3, 2):
            M = cv2.getAffineTransform(pts1, pts2)
            transformed_img_array = cv2.warpAffine(img_array_bgr, M, (cols, rows))
        else:
             st.sidebar.warning("Invalid coordinates for Affine Transform example.")
             transformed_img_array = img_array_bgr
    elif transformation_type == "Perspective Transform":
        st.sidebar.write("Using example points for demonstration.")
        pts1 = np.float32([[56,65],[368,52],[28,387],[389,390]])
        pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])
        if pts1.shape == (4, 2) and pts2.shape == (4, 2):
            M = cv2.getPerspectiveTransform(pts1, pts2)
            transformed_img_array = cv2.warpPerspective(img_array_bgr, M, (300, 300)) # Output size can be different
        else:
            st.sidebar.warning("Invalid coordinates for Perspective Transform example.")
            transformed_img_array = img_array_bgr

    if transformed_img_array is not None:
         st.session_state['processed_image'] = Image.fromarray(cv2.cvtColor(transformed_img_array, cv2.COLOR_BGR2RGB))
         st.session_state['processed_image_caption'] = f"Processed Image ({transformation_type})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"

st.sidebar.title("Filtering & Morphology")
filter_morph_type = st.sidebar.selectbox("Select Operation", ["None", "Gaussian Blur", "Mean Blur", "Median Blur", "Sobel X", "Sobel Y", "Laplacian", "Dilation", "Erosion", "Opening", "Closing"], key='filter_morph_type')

if st.session_state['original_image'] is not None and filter_morph_type != "None":
    img_array = np.array(st.session_state['original_image'])
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
    filtered_morph_img_array = None

    if filter_morph_type == "Gaussian Blur":
        kernel_size_gaussian = st.sidebar.slider("Kernel Size (Gaussian)", 3, 31, 9, step=2, key='gauss_ksize')
        filtered_morph_img_array = cv2.GaussianBlur(img_array_bgr, (kernel_size_gaussian, kernel_size_gaussian), 0)
    elif filter_morph_type == "Mean Blur":
        kernel_size_mean = st.sidebar.slider("Kernel Size (Mean)", 3, 31, 9, step=2, key='mean_ksize')
        filtered_morph_img_array = cv2.blur(img_array_bgr, (kernel_size_mean, kernel_size_mean))
    elif filter_morph_type == "Median Blur":
        kernel_size_median = st.sidebar.slider("Kernel Size (Median)", 3, 31, 9, step=2, key='median_ksize')
        filtered_morph_img_array = cv2.medianBlur(img_array_bgr, kernel_size_median)
    elif filter_morph_type == "Sobel X":
        kernel_size_sobel_x = st.sidebar.slider("Kernel Size (Sobel X)", 3, 31, 3, step=2, key='sobelx_ksize_fm')
        sobelx = cv2.Sobel(img_array_bgr, cv2.CV_64F, 1, 0, ksize=kernel_size_sobel_x)
        filtered_morph_img_array = cv2.convertScaleAbs(sobelx)
    elif filter_morph_type == "Sobel Y":
        kernel_size_sobel_y = st.sidebar.slider("Kernel Size (Sobel Y)", 3, 31, 3, step=2, key='sobely_ksize_fm')
        sobely = cv2.Sobel(img_array_bgr, cv2.CV_64F, 0, 1, ksize=kernel_size_sobel_y)
        filtered_morph_img_array = cv2.convertScaleAbs(sobely)
    elif filter_morph_type == "Laplacian":
        kernel_size_laplacian = st.sidebar.slider("Kernel Size (Laplacian)", 3, 31, 3, step=2, key='laplacian_ksize_fm')
        laplacian = cv2.Laplacian(img_array_bgr, cv2.CV_64F, ksize=kernel_size_laplacian)
        filtered_morph_img_array = cv2.convertScaleAbs(laplacian)
    elif filter_morph_type in ["Dilation", "Erosion", "Opening", "Closing"]:
        kernel_size_morph = st.sidebar.slider("Kernel Size (Morphology)", 1, 15, 3, key='morph_ksize')
        kernel_shape_morph = st.sidebar.selectbox("Kernel Shape", ["Rectangle", "Ellipse", "Cross"], key='morph_shape')

        if kernel_shape_morph == "Rectangle":
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size_morph, kernel_size_morph))
        elif kernel_shape_morph == "Ellipse":
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size_morph, kernel_size_morph))
        elif kernel_shape_morph == "Cross":
            kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (kernel_size_morph, kernel_size_morph))

        if filter_morph_type == "Dilation":
            filtered_morph_img_array = cv2.dilate(img_array_bgr, kernel, iterations=1)
        elif filter_morph_type == "Erosion":
            filtered_morph_img_array = cv2.erode(img_array_bgr, kernel, iterations=1)
        elif filter_morph_type == "Opening":
            filtered_morph_img_array = cv2.morphologyEx(img_array_bgr, cv2.MORPH_OPEN, kernel)
        elif filter_morph_type == "Closing":
            filtered_morph_img_array = cv2.morphologyEx(img_array_bgr, cv2.MORPH_CLOSE, kernel)

    if filtered_morph_img_array is not None:
        if len(filtered_morph_img_array.shape) == 2:
             st.session_state['processed_image'] = Image.fromarray(filtered_morph_img_array, 'L')
        else:
            st.session_state['processed_image'] = Image.fromarray(cv2.cvtColor(filtered_morph_img_array, cv2.COLOR_BGR2RGB))
        st.session_state['processed_image_caption'] = f"Processed Image ({filter_morph_type})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"

st.sidebar.title("Enhancement")
enhancement_type = st.sidebar.selectbox("Select Enhancement", ["None", "Histogram Equalization", "Contrast Stretching", "Sharpening"], key='enhancement_type')

if st.session_state['original_image'] is not None and enhancement_type != "None":
    img_array = np.array(st.session_state['original_image'])
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
    enhanced_img_array = None

    if enhancement_type == "Histogram Equalization":
        if len(img_array_bgr.shape) == 3:
            gray_img = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2GRAY)
        else:
            gray_img = img_array_bgr
        equalized_img = cv2.equalizeHist(gray_img)
        if len(img_array_bgr.shape) == 3:
            enhanced_img_array = cv2.cvtColor(equalized_img, cv2.COLOR_GRAY2BGR)
        else:
            enhanced_img_array = equalized_img
    elif enhancement_type == "Contrast Stretching":
        enhanced_img_array = cv2.normalize(img_array_bgr, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)
    elif enhancement_type == "Sharpening":
        kernel_sharpening = np.array([[-1,-1,-1], [-1, 9,-1], [-1,-1,-1]])
        enhanced_img_array = cv2.filter2D(img_array_bgr, -1, kernel_sharpening)

    if enhanced_img_array is not None:
        if len(enhanced_img_array.shape) == 2:
             st.session_state['processed_image'] = Image.fromarray(enhanced_img_array, 'L')
        else:
            st.session_state['processed_image'] = Image.fromarray(cv2.cvtColor(enhanced_img_array, cv2.COLOR_BGR2RGB))
        st.session_state['processed_image_caption'] = f"Processed Image ({enhancement_type})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"


st.sidebar.title("Edge Detection")
edge_detection_type = st.sidebar.selectbox("Select Edge Detection", ["None", "Sobel", "Canny", "Laplacian"], key='edge_detection_type')

if st.session_state['original_image'] is not None and edge_detection_type != "None":
    img_array = np.array(st.session_state['original_image'])
    if len(img_array.shape) == 3:
        gray_img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
    else:
        gray_img_array = img_array

    edge_detected_img_array = None

    if edge_detection_type == "Sobel":
        sobel_x = st.sidebar.checkbox("Detect X edges", value=True, key='sobel_x_edge')
        sobel_y = st.sidebar.checkbox("Detect Y edges", value=True, key='sobel_y_edge')
        kernel_size_sobel = st.sidebar.slider("Kernel Size (Sobel)", 3, 31, 3, step=2, key='sobel_ksize_edge')
        if sobel_x and sobel_y:
            sobelx = cv2.Sobel(gray_img_array, cv2.CV_64F, 1, 0, ksize=kernel_size_sobel)
            sobely = cv2.Sobel(gray_img_array, cv2.CV_64F, 0, 1, ksize=kernel_size_sobel)
            sobel_combined = np.sqrt(sobelx**2 + sobely**2)
            edge_detected_img_array = cv2.convertScaleAbs(sobel_combined)
        elif sobel_x:
            sobelx = cv2.Sobel(gray_img_array, cv2.CV_64F, 1, 0, ksize=kernel_size_sobel)
            edge_detected_img_array = cv2.convertScaleAbs(sobelx)
        elif sobel_y:
            sobely = cv2.Sobel(gray_img_array, cv2.CV_64F, 0, 1, ksize=kernel_size_sobel)
            edge_detected_img_array = cv2.convertScaleAbs(sobely)
        else:
             edge_detected_img_array = gray_img_array
    elif edge_detection_type == "Canny":
        threshold1 = st.sidebar.slider("Threshold 1 (Canny)", 0, 255, 100, key='canny_thresh1')
        threshold2 = st.sidebar.slider("Threshold 2 (Canny)", 0, 255, 200, key='canny_thresh2')
        aperture_size = st.sidebar.slider("Aperture Size (Canny)", 3, 7, 3, step=2, key='canny_aperture')
        L2gradient = st.sidebar.checkbox("Use L2 gradient", value=False, key='canny_l2')
        edge_detected_img_array = cv2.Canny(gray_img_array, threshold1, threshold2, apertureSize=aperture_size, L2gradient=L2gradient)
    elif edge_detection_type == "Laplacian":
        kernel_size_laplacian = st.sidebar.slider("Kernel Size (Laplacian)", 1, 31, 3, step=2, key='laplacian_ksize_edge')
        laplacian = cv2.Laplacian(gray_img_array, cv2.CV_64F, ksize=kernel_size_laplacian)
        edge_detected_img_array = cv2.convertScaleAbs(laplacian)

    if edge_detected_img_array is not None:
        st.session_state['processed_image'] = Image.fromarray(edge_detected_img_array, 'L')
        st.session_state['processed_image_caption'] = f"Processed Image ({edge_detection_type})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"


# Main content area (for displaying images and results)
st.subheader("Image Display Area")

if st.session_state['original_image'] is not None:
    col1, col2 = st.columns(2)
    with col1:
        st.image(st.session_state['original_image'], caption="Original Image", use_column_width=True)
    with col2:
        if st.session_state['processed_image'] is not None:
            st.image(st.session_state['processed_image'], caption=st.session_state['processed_image_caption'], use_column_width=True)
        else:
            st.write("Apply an operation to see the processed image.")

"""## Summary:

### Data Analysis Key Findings
*   The application successfully implemented a Streamlit GUI with a sidebar containing distinct sections for "Menu", "Image Info", "Color Conversions", "Transformations", "Filtering & Morphology", "Enhancement", and "Edge Detection".
*   The "Image Info" section displays key properties of the uploaded image, including resolution, shape, format, channels, and DPI (if available).
*   Various image processing operations were integrated using OpenCV, including:
    *   Color Conversions (RGB ‚Üî BGR, RGB ‚Üî HSV, RGB ‚Üî YCbCr, RGB ‚Üî Grayscale)
    *   Transformations (Rotation, Scaling, Translation, Affine Transform, Perspective Transform), with interactive controls for parameters.
    *   Filtering & Morphology (Gaussian, Mean, Median, Sobel, Laplacian, Dilation, Erosion, Opening, Closing), with adjustable kernel sizes and shapes.
    *   Enhancement (Histogram Equalization, Contrast Stretching, Sharpening).
    *   Edge Detection (Sobel, Canny, Laplacian), with parameters for customization.
*   A "Save As" option was added to the file menu, allowing the processed image to be downloaded in JPG, PNG, or BMP formats. The JPG format includes a quality slider, and the file size of the saved image is displayed.
*   The application effectively uses Streamlit's session state to manage the original and processed images, ensuring that the displayed processed image reflects the last applied operation.
*   The original and processed images are displayed side-by-side in the main content area using Streamlit columns, with dynamic captions indicating the applied operation.

### Insights or Next Steps
*   Implement the "Exit" functionality in the File menu.
*   Enhance the "Save As" section to include options for comparing file sizes and visual quality across different formats and compression levels.

# Task
Implement the "Exit" functionality in the File menu and enhance the "Save As" section to include options for comparing file sizes and visual quality across different formats and compression levels in the Streamlit application.

## Implement exit functionality

### Subtask:
Add code to the "Exit" option in the File menu to stop the Streamlit application.

**Reasoning**:
Implement the "Exit" functionality by adding `st.stop()` within the `if file_operation == "Exit":` block to stop the Streamlit application when the user selects Exit.

## Add edge detection section

### Subtask:
Include options for edge detection algorithms (Sobel, Canny, Laplacian) and integrate the OpenCV code.

**Reasoning**:
Add the "Edge Detection" section to the sidebar, create a selectbox for different edge detection methods, and implement the OpenCV code for Sobel, Canny, and Laplacian edge detection, including parameter inputs and displaying the resulting image.
"""

import cv2
import numpy as np
from PIL import Image

# Edge Detection Section
st.sidebar.title("Edge Detection")
edge_detection_type = st.sidebar.selectbox("Select Edge Detection", ["None", "Sobel", "Canny", "Laplacian"])

edge_detected_image = None

if image is not None:
    img_array = np.array(image)
    # Convert to grayscale for edge detection if it's a color image
    if len(img_array.shape) == 3:
        gray_img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
    else:
        gray_img_array = img_array # Already grayscale

    if edge_detection_type == "Sobel":
        st.sidebar.write("Sobel Edge Detection Parameters:")
        sobel_x = st.sidebar.checkbox("Detect X edges", value=True)
        sobel_y = st.sidebar.checkbox("Detect Y edges", value=True)
        kernel_size_sobel = st.sidebar.slider("Kernel Size (Sobel)", 3, 31, 3, step=2)

        if sobel_x and sobel_y:
            sobelx = cv2.Sobel(gray_img_array, cv2.CV_64F, 1, 0, ksize=kernel_size_sobel)
            sobely = cv2.Sobel(gray_img_array, cv2.CV_64F, 0, 1, ksize=kernel_size_sobel)
            sobel_combined = np.sqrt(sobelx**2 + sobely**2)
            edge_detected_img_array = cv2.convertScaleAbs(sobel_combined)
        elif sobel_x:
            sobelx = cv2.Sobel(gray_img_array, cv2.CV_64F, 1, 0, ksize=kernel_size_sobel)
            edge_detected_img_array = cv2.convertScaleAbs(sobelx)
        elif sobel_y:
            sobely = cv2.Sobel(gray_img_array, cv2.CV_64F, 0, 1, ksize=kernel_size_sobel)
            edge_detected_img_array = cv2.convertScaleAbs(sobely)
        else:
             edge_detected_img_array = gray_img_array # No detection selected

    elif edge_detection_type == "Canny":
        st.sidebar.write("Canny Edge Detection Parameters:")
        threshold1 = st.sidebar.slider("Threshold 1 (Canny)", 0, 255, 100)
        threshold2 = st.sidebar.slider("Threshold 2 (Canny)", 0, 255, 200)
        aperture_size = st.sidebar.slider("Aperture Size (Canny)", 3, 7, 3, step=2)
        L2gradient = st.sidebar.checkbox("Use L2 gradient", value=False)

        edge_detected_img_array = cv2.Canny(gray_img_array, threshold1, threshold2, apertureSize=aperture_size, L2gradient=L2gradient)

    elif edge_detection_type == "Laplacian":
        st.sidebar.write("Laplacian Edge Detection Parameters:")
        kernel_size_laplacian = st.sidebar.slider("Kernel Size (Laplacian)", 1, 31, 3, step=2)

        laplacian = cv2.Laplacian(gray_img_array, cv2.CV_64F, ksize=kernel_size_laplacian)
        edge_detected_img_array = cv2.convertScaleAbs(laplacian)
    elif edge_detection_type == "None":
        # If no edge detection is selected, use the grayscale image for consistency in the pipeline
        edge_detected_img_array = gray_img_array


    # Convert the processed NumPy array (grayscale) back to a PIL Image
    edge_detected_image = Image.fromarray(edge_detected_img_array, 'L') # 'L' mode for grayscale

# Display images side-by-side, prioritizing edge detection
if image is not None:
    col1, col2 = st.columns(2)
    with col1:
        st.image(image, caption="Original Image", use_column_width=True)
    with col2:
        if edge_detected_image is not None and edge_detection_type != "None":
            st.image(edge_detected_image, caption=f"Processed Image ({edge_detection_type})", use_column_width=True)
        elif enhanced_image is not None and enhancement_type != "None":
            st.image(enhanced_image, caption=f"Processed Image ({enhancement_type})", use_column_width=True)
        elif filtered_morph_image is not None and filter_morph_type != "None":
             st.image(filtered_morph_image, caption=f"Processed Image ({filter_morph_type})", use_column_width=True)
        elif transformed_image is not None and transformation_type != "None":
             st.image(transformed_image, caption=f"Processed Image ({transformation_type})", use_column_width=True)
        elif processed_image is not None and color_conversion != "None":
             st.image(processed_image, caption=f"Processed Image ({color_conversion})", use_column_width=True)
        else:
            st.write("Select an operation to see the processed image.")

import streamlit as st
from PIL import Image
import numpy as np
import cv2
import io

st.set_page_config(layout="wide")

st.title("Image Processing Application")

# Use Streamlit's session state to manage the original and processed images
if 'original_image' not in st.session_state:
    st.session_state['original_image'] = None
if 'processed_image' not in st.session_state:
    st.session_state['processed_image'] = None
if 'processed_image_caption' not in st.session_state:
     st.session_state['processed_image_caption'] = "Processed Image"


# Menu Bar
st.sidebar.title("Menu")

# File operations
file_operation = st.sidebar.selectbox("File", ["", "Open", "Save As", "Exit"], key='file_op')

if file_operation == "Open":
    uploaded_file = st.sidebar.file_uploader("Choose an image...", type=["jpg", "jpeg", "png", "bmp", "tiff"], key='file_uploader')
    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        st.session_state['original_image'] = image
        st.session_state['processed_image'] = image # Initially, processed is the same as original
        st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"
elif file_operation == "Save As":
    if st.session_state['processed_image'] is not None:
        st.sidebar.subheader("Save Options")
        output_format = st.sidebar.selectbox("Select output format", ["PNG", "JPEG", "BMP"], key='save_format')

        img_byte_arr = io.BytesIO()
        file_extension = "png"
        mime_type = "image/png"

        if output_format == "JPEG":
            jpeg_quality = st.sidebar.slider("JPEG Quality", 0, 100, 95, key='jpeg_quality')
            st.session_state['processed_image'].save(img_byte_arr, format='JPEG', quality=jpeg_quality)
            file_extension = "jpg"
            mime_type = "image/jpeg"
        elif output_format == "PNG":
             st.session_state['processed_image'].save(img_byte_arr, format='PNG')
             file_extension = "png"
             mime_type = "image/png"
        elif output_format == "BMP":
             st.session_state['processed_image'].save(img_byte_arr, format='BMP')
             file_extension = "bmp"
             mime_type = "image/bmp"

        st.sidebar.download_button(
            label=f"Download Image as {output_format}",
            data=img_byte_arr.getvalue(),
            file_name=f"processed_image.{file_extension}",
            mime=mime_type,
            key='download_button'
        )
        st.sidebar.write(f"File size: {len(img_byte_arr.getvalue()) / 1024:.2f} KB")

    else:
        st.sidebar.warning("No image to save. Please open an image first.")

elif file_operation == "Exit":
    st.stop()


# Sidebar Sections (Organized)
st.sidebar.title("Image Info")
if st.session_state['original_image'] is not None:
    img_info = st.session_state['original_image']
    st.sidebar.write(f"Resolution: {img_info.width} x {img_info.height}")
    st.sidebar.write(f"Shape: {np.array(img_info).shape}")
    if img_info.info and 'dpi' in img_info.info:
        st.sidebar.write(f"DPI: {img_info.info['dpi']}")
    else:
        st.sidebar.write("DPI: N/A")
    st.sidebar.write(f"Format: {img_info.format}")
    st.sidebar.write(f"Channels: {len(img_info.getbands())}")
else:
    st.sidebar.write("No image loaded yet.")


st.sidebar.title("Color Conversions")
color_conversion = st.sidebar.selectbox("Select Conversion", ["None", "RGB to BGR", "BGR to RGB", "RGB to HSV", "HSV to RGB", "RGB to YCbCr", "YCbCr to RGB", "RGB to Grayscale"], key='color_conversion')

if st.session_state['original_image'] is not None and color_conversion != "None":
    img_array = np.array(st.session_state['original_image'])
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)

    processed_img_array = None

    if color_conversion == "RGB to BGR":
        processed_img_array = img_array_bgr # Already in BGR for processing
    elif color_conversion == "BGR to RGB":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2RGB)
    elif color_conversion == "RGB to HSV":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2HSV)
    elif color_conversion == "HSV to RGB":
        img_array_hsv = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2HSV)
        processed_img_array = cv2.cvtColor(img_array_hsv, cv2.COLOR_HSV2RGB)
    elif color_conversion == "RGB to YCbCr":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2YCR_CB)
    elif color_conversion == "YCbCr to RGB":
        img_array_ycbcr = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2YCR_CB)
        processed_img_array = cv2.cvtColor(img_array_ycbcr, cv2.COLOR_YCR_CB2RGB)
    elif color_conversion == "RGB to Grayscale":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2GRAY)

    if processed_img_array is not None:
        if len(processed_img_array.shape) == 2:
             st.session_state['processed_image'] = Image.fromarray(processed_img_array, 'L')
        else:
            # Assuming color conversions result in BGR, convert to RGB for PIL display
             st.session_state['processed_image'] = Image.fromarray(cv2.cvtColor(processed_img_array, cv2.COLOR_BGR2RGB))
        st.session_state['processed_image_caption'] = f"Processed Image ({color_conversion})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"


st.sidebar.title("Transformations")
transformation_type = st.sidebar.selectbox("Select Transformation", ["None", "Rotation", "Scaling", "Translation", "Affine Transform", "Perspective Transform"], key='transformation_type')

if st.session_state['original_image'] is not None and transformation_type != "None":
    img_array = np.array(st.session_state['original_image'])
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
    rows, cols, _ = img_array_bgr.shape
    transformed_img_array = None

    if transformation_type == "Rotation":
        angle = st.sidebar.slider("Angle (degrees)", -180, 180, 0, key='rot_angle')
        M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)
        transformed_img_array = cv2.warpAffine(img_array_bgr, M, (cols, rows))
    elif transformation_type == "Scaling":
        scale_x = st.sidebar.slider("Scale X", 0.1, 5.0, 1.0, key='scale_x')
        scale_y = st.sidebar.slider("Scale Y", 0.1, 5.0, 1.0, key='scale_y')
        transformed_img_array = cv2.resize(img_array_bgr, None, fx=scale_x, fy=scale_y, interpolation=cv2.INTER_LINEAR)
    elif transformation_type == "Translation":
        tx = st.sidebar.slider("Translate X", -cols, cols, 0, key='trans_x')
        ty = st.sidebar.slider("Translate Y", -rows, rows, 0, key='trans_y')
        M = np.float32([[1, 0, tx], [0, 1, ty]])
        transformed_img_array = cv2.warpAffine(img_array_bgr, M, (cols, rows))
    elif transformation_type == "Affine Transform":
        st.sidebar.write("Using example points for demonstration.")
        pts1 = np.float32([[50,50],[200,50],[50,200]])
        pts2 = np.float32([[10,100],[200,50],[100,250]])
        if pts1.shape == (3, 2) and pts2.shape == (3, 2):
            M = cv2.getAffineTransform(pts1, pts2)
            transformed_img_array = cv2.warpAffine(img_array_bgr, M, (cols, rows))
        else:
             st.sidebar.warning("Invalid coordinates for Affine Transform example.")
             transformed_img_array = img_array_bgr
    elif transformation_type == "Perspective Transform":
        st.sidebar.write("Using example points for demonstration.")
        pts1 = np.float32([[56,65],[368,52],[28,387],[389,390]])
        pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])
        if pts1.shape == (4, 2) and pts2.shape == (4, 2):
            M = cv2.getPerspectiveTransform(pts1, pts2)
            transformed_img_array = cv2.warpPerspective(img_array_bgr, M, (300, 300)) # Output size can be different
        else:
            st.sidebar.warning("Invalid coordinates for Perspective Transform example.")
            transformed_img_array = img_array_bgr

    if transformed_img_array is not None:
         st.session_state['processed_image'] = Image.fromarray(cv2.cvtColor(transformed_img_array, cv2.COLOR_BGR2RGB))
         st.session_state['processed_image_caption'] = f"Processed Image ({transformation_type})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"

st.sidebar.title("Filtering & Morphology")
filter_morph_type = st.sidebar.selectbox("Select Operation", ["None", "Gaussian Blur", "Mean Blur", "Median Blur", "Sobel X", "Sobel Y", "Laplacian", "Dilation", "Erosion", "Opening", "Closing"], key='filter_morph_type')

if st.session_state['original_image'] is not None and filter_morph_type != "None":
    img_array = np.array(st.session_state['original_image'])
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
    filtered_morph_img_array = None

    if filter_morph_type == "Gaussian Blur":
        kernel_size_gaussian = st.sidebar.slider("Kernel Size (Gaussian)", 3, 31, 9, step=2, key='gauss_ksize')
        filtered_morph_img_array = cv2.GaussianBlur(img_array_bgr, (kernel_size_gaussian, kernel_size_gaussian), 0)
    elif filter_morph_type == "Mean Blur":
        kernel_size_mean = st.sidebar.slider("Kernel Size (Mean)", 3, 31, 9, step=2, key='mean_ksize')
        filtered_morph_img_array = cv2.blur(img_array_bgr, (kernel_size_mean, kernel_size_mean))
    elif filter_morph_type == "Median Blur":
        kernel_size_median = st.sidebar.slider("Kernel Size (Median)", 3, 31, 9, step=2, key='median_ksize')
        filtered_morph_img_array = cv2.medianBlur(img_array_bgr, kernel_size_median)
    elif filter_morph_type == "Sobel X":
        kernel_size_sobel_x = st.sidebar.slider("Kernel Size (Sobel X)", 3, 31, 3, step=2, key='sobelx_ksize_fm')
        sobelx = cv2.Sobel(img_array_bgr, cv2.CV_64F, 1, 0, ksize=kernel_size_sobel_x)
        filtered_morph_img_array = cv2.convertScaleAbs(sobelx)
    elif filter_morph_type == "Sobel Y":
        kernel_size_sobel_y = st.sidebar.slider("Kernel Size (Sobel Y)", 3, 31, 3, step=2, key='sobely_ksize_fm')
        sobely = cv2.Sobel(img_array_bgr, cv2.CV_64F, 0, 1, ksize=kernel_size_sobel_y)
        filtered_morph_img_array = cv2.convertScaleAbs(sobely)
    elif filter_morph_type == "Laplacian":
        kernel_size_laplacian = st.sidebar.slider("Kernel Size (Laplacian)", 3, 31, 3, step=2, key='laplacian_ksize_fm')
        laplacian = cv2.Laplacian(img_array_bgr, cv2.CV_64F, ksize=kernel_size_laplacian)
        filtered_morph_img_array = cv2.convertScaleAbs(laplacian)
    elif filter_morph_type in ["Dilation", "Erosion", "Opening", "Closing"]:
        kernel_size_morph = st.sidebar.slider("Kernel Size (Morphology)", 1, 15, 3, key='morph_ksize')
        kernel_shape_morph = st.sidebar.selectbox("Kernel Shape", ["Rectangle", "Ellipse", "Cross"], key='morph_shape')

        if kernel_shape_morph == "Rectangle":
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size_morph, kernel_size_morph))
        elif kernel_shape_morph == "Ellipse":
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size_morph, kernel_size_morph))
        elif kernel_shape_morph == "Cross":
            kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (kernel_size_morph, kernel_size_morph))

        if filter_morph_type == "Dilation":
            filtered_morph_img_array = cv2.dilate(img_array_bgr, kernel, iterations=1)
        elif filter_morph_type == "Erosion":
            filtered_morph_img_array = cv2.erode(img_array_bgr, kernel, iterations=1)
        elif filter_morph_type == "Opening":
            filtered_morph_img_array = cv2.morphologyEx(img_array_bgr, cv2.MORPH_OPEN, kernel)
        elif filter_morph_type == "Closing":
            filtered_morph_img_array = cv2.morphologyEx(img_array_bgr, cv2.MORPH_CLOSE, kernel)

    if filtered_morph_img_array is not None:
        if len(filtered_morph_img_array.shape) == 2:
             st.session_state['processed_image'] = Image.fromarray(filtered_morph_img_array, 'L')
        else:
            st.session_state['processed_image'] = Image.fromarray(cv2.cvtColor(filtered_morph_img_array, cv2.COLOR_BGR2RGB))
        st.session_state['processed_image_caption'] = f"Processed Image ({filter_morph_type})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"

st.sidebar.title("Enhancement")
enhancement_type = st.sidebar.selectbox("Select Enhancement", ["None", "Histogram Equalization", "Contrast Stretching", "Sharpening"], key='enhancement_type')

if st.session_state['original_image'] is not None and enhancement_type != "None":
    img_array = np.array(st.session_state['original_image'])
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
    enhanced_img_array = None

    if enhancement_type == "Histogram Equalization":
        if len(img_array_bgr.shape) == 3:
            gray_img = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2GRAY)
        else:
            gray_img = img_array_bgr
        equalized_img = cv2.equalizeHist(gray_img)
        if len(img_array_bgr.shape) == 3:
            enhanced_img_array = cv2.cvtColor(equalized_img, cv2.COLOR_GRAY2BGR)
        else:
            enhanced_img_array = equalized_img
    elif enhancement_type == "Contrast Stretching":
        enhanced_img_array = cv2.normalize(img_array_bgr, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)
    elif enhancement_type == "Sharpening":
        kernel_sharpening = np.array([[-1,-1,-1], [-1, 9,-1], [-1,-1,-1]])
        enhanced_img_array = cv2.filter2D(img_array_bgr, -1, kernel_sharpening)

    if enhanced_img_array is not None:
        if len(enhanced_img_array.shape) == 2:
             st.session_state['processed_image'] = Image.fromarray(enhanced_img_array, 'L')
        else:
            st.session_state['processed_image'] = Image.fromarray(cv2.cvtColor(enhanced_img_array, cv2.COLOR_BGR2RGB))
        st.session_state['processed_image_caption'] = f"Processed Image ({enhancement_type})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"


st.sidebar.title("Edge Detection")
edge_detection_type = st.sidebar.selectbox("Select Edge Detection", ["None", "Sobel", "Canny", "Laplacian"], key='edge_detection_type')

if st.session_state['original_image'] is not None and edge_detection_type != "None":
    img_array = np.array(st.session_state['original_image'])
    if len(img_array.shape) == 3:
        gray_img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
    else:
        gray_img_array = img_array

    edge_detected_img_array = None

    if edge_detection_type == "Sobel":
        sobel_x = st.sidebar.checkbox("Detect X edges", value=True, key='sobel_x_edge')
        sobel_y = st.sidebar.checkbox("Detect Y edges", value=True, key='sobel_y_edge')
        kernel_size_sobel = st.sidebar.slider("Kernel Size (Sobel)", 3, 31, 3, step=2, key='sobel_ksize_edge')
        if sobel_x and sobel_y:
            sobelx = cv2.Sobel(gray_img_array, cv2.CV_64F, 1, 0, ksize=kernel_size_sobel)
            sobely = cv2.Sobel(gray_img_array, cv2.CV_64F, 0, 1, ksize=kernel_size_sobel)
            sobel_combined = np.sqrt(sobelx**2 + sobely**2)
            edge_detected_img_array = cv2.convertScaleAbs(sobel_combined)
        elif sobel_x:
            sobelx = cv2.Sobel(gray_img_array, cv2.CV_64F, 1, 0, ksize=kernel_size_sobel)
            edge_detected_img_array = cv2.convertScaleAbs(sobelx)
        elif sobel_y:
            sobely = cv2.Sobel(gray_img_array, cv2.CV_64F, 0, 1, ksize=kernel_size_sobel)
            edge_detected_img_array = cv2.convertScaleAbs(sobely)
        else:
             edge_detected_img_array = gray_img_array
    elif edge_detection_type == "Canny":
        threshold1 = st.sidebar.slider("Threshold 1 (Canny)", 0, 255, 100, key='canny_thresh1')
        threshold2 = st.sidebar.slider("Threshold 2 (Canny)", 0, 255, 200, key='canny_thresh2')
        aperture_size = st.sidebar.slider("Aperture Size (Canny)", 3, 7, 3, step=2, key='canny_aperture')
        L2gradient = st.sidebar.checkbox("Use L2 gradient", value=False, key='canny_l2')
        edge_detected_img_array = cv2.Canny(gray_img_array, threshold1, threshold2, apertureSize=aperture_size, L2gradient=L2gradient)
    elif edge_detection_type == "Laplacian":
        kernel_size_laplacian = st.sidebar.slider("Kernel Size (Laplacian)", 1, 31, 3, step=2, key='laplacian_ksize_edge')
        laplacian = cv2.Laplacian(gray_img_array, cv2.CV_64F, ksize=kernel_size_laplacian)
        edge_detected_img_array = cv2.convertScaleAbs(laplacian)

    if edge_detected_img_array is not None:
        st.session_state['processed_image'] = Image.fromarray(edge_detected_img_array, 'L')
        st.session_state['processed_image_caption'] = f"Processed Image ({edge_detection_type})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"


# Main content area (for displaying images and results)
st.subheader("Image Display Area")

if st.session_state['original_image'] is not None:
    col1, col2 = st.columns(2)
    with col1:
        st.image(st.session_state['original_image'], caption="Original Image", use_column_width=True)
    with col2:
        if st.session_state['processed_image'] is not None:
            st.image(st.session_state['processed_image'], caption=st.session_state['processed_image_caption'], use_column_width=True)
        else:
            st.write("Apply an operation to see the processed image.")

"""Install dependencies: pip install streamlit opencv-python numpy matplotlib

Create base app.py with Streamlit layout:

Sidebar (operations menu)
Image upload widget
Two image display placeholders
"""

# Install dependencies (can be in a separate cell if preferred in Colab)
# !pip install streamlit opencv-python numpy matplotlib

import streamlit as st
from PIL import Image
import numpy as np
import cv2

st.set_page_config(layout="wide")

st.title("Image Processing Application")

# Sidebar for operations
st.sidebar.title("Operations")

# Image upload widget
uploaded_file = st.sidebar.file_uploader("Choose an image...", type=["jpg", "jpeg", "png", "bmp", "tiff"])

image = None
if uploaded_file is not None:
    image = Image.open(uploaded_file)

# Image display placeholders
st.subheader("Original Image")
if image is not None:
    st.image(image, caption="Original Image", use_column_width=True)
else:
    st.write("Upload an image to get started.")

st.subheader("Processed Image")
# This will be updated later with processed images
st.write("Processed image will appear here.")

!streamlit run /usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py

"""
Phase 2 ‚Äì Image Fundamentals Module
Implement:

Load and represent image as NumPy array
Display image shape & channel information.
Perform color conversions (RGB, HSV, YCbCr, Gray) using both mathematical formulas and OpenCV functions."""

import streamlit as st
from PIL import Image
import numpy as np
import cv2

st.set_page_config(layout="wide")

st.title("Image Processing Application")

# Use Streamlit's session state to manage the original and processed images
if 'original_image' not in st.session_state:
    st.session_state['original_image'] = None
if 'processed_image' not in st.session_state:
    st.session_state['processed_image'] = None
if 'processed_image_caption' not in st.session_state:
     st.session_state['processed_image_caption'] = "Processed Image"


# Sidebar for operations
st.sidebar.title("Operations")

# Image upload widget
uploaded_file = st.sidebar.file_uploader("Choose an image...", type=["jpg", "jpeg", "png", "bmp", "tiff"], key='file_uploader')

if uploaded_file is not None:
    image = Image.open(uploaded_file)
    st.session_state['original_image'] = image
    st.session_state['processed_image'] = image # Initially, processed is the same as original
    st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"

# Image Info Section (basic - shape and channels for now, full info in a later step)
if st.session_state['original_image'] is not None:
    img_array = np.array(st.session_state['original_image'])
    st.sidebar.subheader("Image Info (Basic)")
    st.sidebar.write(f"Shape: {img_array.shape}")
    st.sidebar.write(f"Channels: {img_array.shape[2] if len(img_array.shape) == 3 else 1}")


# Color Conversions Section
st.sidebar.subheader("Color Conversions")
color_conversion = st.sidebar.selectbox("Select Conversion", ["None", "RGB to BGR", "BGR to RGB", "RGB to HSV", "HSV to RGB", "RGB to YCbCr", "YCbCr to RGB", "RGB to Grayscale"], key='color_conversion')

if st.session_state['original_image'] is not None and color_conversion != "None":
    img_array = np.array(st.session_state['original_image'])
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)

    processed_img_array = None

    if color_conversion == "RGB to BGR":
        processed_img_array = img_array_bgr # Already in BGR for processing
    elif color_conversion == "BGR to RGB":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2RGB)
    elif color_conversion == "RGB to HSV":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2HSV)
    elif color_conversion == "HSV to RGB":
        img_array_hsv = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2HSV)
        processed_img_array = cv2.cvtColor(img_array_hsv, cv2.COLOR_HSV2RGB)
    elif color_conversion == "RGB to YCbCr":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2YCR_CB)
    elif color_conversion == "YCbCr to RGB":
        img_array_ycbcr = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2YCR_CB)
        processed_img_array = cv2.cvtColor(img_array_ycbcr, cv2.COLOR_YCR_CB2RGB)
    elif color_conversion == "RGB to Grayscale":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2GRAY)

    if processed_img_array is not None:
        if len(processed_img_array.shape) == 2:
             st.session_state['processed_image'] = Image.fromarray(processed_img_array, 'L')
        else:
            # Assuming color conversions result in BGR, convert to RGB for PIL display
             st.session_state['processed_image'] = Image.fromarray(cv2.cvtColor(processed_img_array, cv2.COLOR_BGR2RGB))
        st.session_state['processed_image_caption'] = f"Processed Image ({color_conversion})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"


# Main content area (for displaying images and results)
st.subheader("Image Display Area")

if st.session_state['original_image'] is not None:
    col1, col2 = st.columns(2)
    with col1:
        st.image(st.session_state['original_image'], caption="Original Image", use_column_width=True)
    with col2:
        if st.session_state['processed_image'] is not None:
            st.image(st.session_state['processed_image'], caption=st.session_state['processed_image_caption'], use_column_width=True)
        else:
            st.write("Apply an operation to see the processed image.")

"""Phase 3 ‚Äì Transformations & Bitwise Ops
Implement rotation, scaling, translation, affine, perspective
Add bitwise AND, OR, XOR, NOT
"""

import streamlit as st
from PIL import Image
import numpy as np
import cv2

st.set_page_config(layout="wide")

st.title("Image Processing Application")

# Use Streamlit's session state to manage the original and processed images
if 'original_image' not in st.session_state:
    st.session_state['original_image'] = None
if 'processed_image' not in st.session_state:
    st.session_state['processed_image'] = None
if 'processed_image_caption' not in st.session_state:
     st.session_state['processed_image_caption'] = "Processed Image"


# Sidebar for operations
st.sidebar.title("Operations")

# Image upload widget
uploaded_file = st.sidebar.file_uploader("Choose an image...", type=["jpg", "jpeg", "png", "bmp", "tiff"], key='file_uploader')

if uploaded_file is not None:
    image = Image.open(uploaded_file)
    st.session_state['original_image'] = image
    st.session_state['processed_image'] = image # Initially, processed is the same as original
    st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"

# Image Info Section (basic - shape and channels for now, full info in a later step)
if st.session_state['original_image'] is not None:
    img_array = np.array(st.session_state['original_image'])
    st.sidebar.subheader("Image Info (Basic)")
    st.sidebar.write(f"Shape: {img_array.shape}")
    st.sidebar.write(f"Channels: {img_array.shape[2] if len(img_array.shape) == 3 else 1}")


# Color Conversions Section
st.sidebar.subheader("Color Conversions")
color_conversion = st.sidebar.selectbox("Select Conversion", ["None", "RGB to BGR", "BGR to RGB", "RGB to HSV", "HSV to RGB", "RGB to YCbCr", "YCbCr to RGB", "RGB to Grayscale"], key='color_conversion')

if st.session_state['original_image'] is not None and color_conversion != "None":
    img_array = np.array(st.session_state['original_image'])
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)

    processed_img_array = None

    if color_conversion == "RGB to BGR":
        processed_img_array = img_array_bgr # Already in BGR for processing
    elif color_conversion == "BGR to RGB":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2RGB)
    elif color_conversion == "RGB to HSV":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2HSV)
    elif color_conversion == "HSV to RGB":
        img_array_hsv = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2HSV)
        processed_img_array = cv2.cvtColor(img_array_hsv, cv2.COLOR_HSV2RGB)
    elif color_conversion == "RGB to YCbCr":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2YCR_CB)
    elif color_conversion == "YCbCr to RGB":
        img_array_ycbcr = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2YCR_CB)
        processed_img_array = cv2.cvtColor(img_array_ycbcr, cv2.COLOR_YCR_CB2RGB)
    elif color_conversion == "RGB to Grayscale":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2GRAY)

    if processed_img_array is not None:
        if len(processed_img_array.shape) == 2:
             st.session_state['processed_image'] = Image.fromarray(processed_img_array, 'L')
        else:
            # Assuming color conversions result in BGR, convert to RGB for PIL display
             st.session_state['processed_image'] = Image.fromarray(cv2.cvtColor(processed_img_array, cv2.COLOR_BGR2RGB))
        st.session_state['processed_image_caption'] = f"Processed Image ({color_conversion})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"


st.sidebar.title("Transformations")
transformation_type = st.sidebar.selectbox("Select Transformation", ["None", "Rotation", "Scaling", "Translation", "Affine Transform", "Perspective Transform"], key='transformation_type')

if st.session_state['original_image'] is not None and transformation_type != "None":
    img_array = np.array(st.session_state['original_image'])
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
    rows, cols, _ = img_array_bgr.shape
    transformed_img_array = None

    if transformation_type == "Rotation":
        angle = st.sidebar.slider("Angle (degrees)", -180, 180, 0, key='rot_angle')
        M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)
        transformed_img_array = cv2.warpAffine(img_array_bgr, M, (cols, rows))
    elif transformation_type == "Scaling":
        scale_x = st.sidebar.slider("Scale X", 0.1, 5.0, 1.0, key='scale_x')
        scale_y = st.sidebar.slider("Scale Y", 0.1, 5.0, 1.0, key='scale_y')
        transformed_img_array = cv2.resize(img_array_bgr, None, fx=scale_x, fy=scale_y, interpolation=cv2.INTER_LINEAR)
    elif transformation_type == "Translation":
        tx = st.sidebar.slider("Translate X", -cols, cols, 0, key='trans_x')
        ty = st.sidebar.slider("Translate Y", -rows, rows, 0, key='trans_y')
        M = np.float32([[1, 0, tx], [0, 1, ty]])
        transformed_img_array = cv2.warpAffine(img_array_bgr, M, (cols, rows))
    elif transformation_type == "Affine Transform":
        st.sidebar.write("Using example points for demonstration.")
        # Example points - in a real app, user interaction would be needed
        pts1 = np.float32([[50,50],[200,50],[50,200]])
        pts2 = np.float32([[10,100],[200,50],[100,250]])
        if pts1.shape == (3, 2) and pts2.shape == (3, 2):
            M = cv2.getAffineTransform(pts1, pts2)
            transformed_img_array = cv2.warpAffine(img_array_bgr, M, (cols, rows))
        else:
             st.sidebar.warning("Invalid coordinates for Affine Transform example.")
             transformed_img_array = img_array_bgr
    elif transformation_type == "Perspective Transform":
        st.sidebar.write("Using example points for demonstration.")
        # Example points - in a real app, user interaction would be needed
        pts1 = np.float32([[56,65],[368,52],[28,387],[389,390]])
        pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])
        if pts1.shape == (4, 2) and pts2.shape == (4, 2):
            M = cv2.getPerspectiveTransform(pts1, pts2)
            transformed_img_array = cv2.warpPerspective(img_array_bgr, M, (300, 300)) # Output size can be different
        else:
            st.sidebar.warning("Invalid coordinates for Perspective Transform example.")
            transformed_img_array = img_array_bgr

    if transformed_img_array is not None:
         st.session_state['processed_image'] = Image.fromarray(cv2.cvtColor(transformed_img_array, cv2.COLOR_BGR2RGB))
         st.session_state['processed_image_caption'] = f"Processed Image ({transformation_type})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"

st.sidebar.title("Bitwise Operations")
bitwise_type = st.sidebar.selectbox("Select Operation", ["None", "AND", "OR", "XOR", "NOT"], key='bitwise_type')

if st.session_state['original_image'] is not None and bitwise_type != "None":
    img_array = np.array(st.session_state['original_image'])
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
    bitwise_img_array = None

    # For bitwise operations, we typically need a second image or a mask.
    # For demonstration, let's create a simple mask or use a predefined image.
    # A real application would allow uploading a second image or creating a mask dynamically.
    st.sidebar.write("Note: Bitwise operations typically require a second image or a mask.")
    st.sidebar.write("Using a simple example mask for demonstration (a white rectangle).")

    # Create a dummy mask
    mask = np.zeros(img_array_bgr.shape[:2], dtype="uint8")
    center_x, center_y = img_array_bgr.shape[1] // 2, img_array_bgr.shape[0] // 2
    mask = cv2.rectangle(mask, (center_x - 100, center_y - 100), (center_x + 100, center_y + 100), 255, -1)

    if bitwise_type == "AND":
        bitwise_img_array = cv2.bitwise_and(img_array_bgr, img_array_bgr, mask=mask)
    elif bitwise_type == "OR":
        bitwise_img_array = cv2.bitwise_or(img_array_bgr, img_array_bgr, mask=mask)
    elif bitwise_type == "XOR":
        bitwise_img_array = cv2.bitwise_xor(img_array_bgr, img_array_bgr, mask=mask)
    elif bitwise_type == "NOT":
        bitwise_img_array = cv2.bitwise_not(img_array_bgr, mask=mask)


    if bitwise_img_array is not None:
        st.session_state['processed_image'] = Image.fromarray(cv2.cvtColor(bitwise_img_array, cv2.COLOR_BGR2RGB))
        st.session_state['processed_image_caption'] = f"Processed Image ({bitwise_type})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"


# Main content area (for displaying images and results)
st.subheader("Image Display Area")

if st.session_state['original_image'] is not None:
    col1, col2 = st.columns(2)
    with col1:
        st.image(st.session_state['original_image'], caption="Original Image", use_column_width=True)
    with col2:
        if st.session_state['processed_image'] is not None:
            st.image(st.session_state['processed_image'], caption=st.session_state['processed_image_caption'], use_column_width=True)
        else:
            st.write("Apply an operation to see the processed image.")

"""Phase 4 ‚Äì Filtering & Morphology
Gaussian, Median, Mean smoothing
Sobel, Laplacian
Dilation, Erosion, Opening, Closing
"""

import streamlit as st
from PIL import Image
import numpy as np
import cv2

st.set_page_config(layout="wide")

st.title("Image Processing Application")

# Use Streamlit's session state to manage the original and processed images
if 'original_image' not in st.session_state:
    st.session_state['original_image'] = None
if 'processed_image' not in st.session_state:
    st.session_state['processed_image'] = None
if 'processed_image_caption' not in st.session_state:
     st.session_state['processed_image_caption'] = "Processed Image"


# Sidebar for operations
st.sidebar.title("Operations")

# Image upload widget
uploaded_file = st.sidebar.file_uploader("Choose an image...", type=["jpg", "jpeg", "png", "bmp", "tiff"], key='file_uploader')

if uploaded_file is not None:
    image = Image.open(uploaded_file)
    st.session_state['original_image'] = image
    st.session_state['processed_image'] = image # Initially, processed is the same as original
    st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"

# Image Info Section (basic - shape and channels for now, full info in a later step)
if st.session_state['original_image'] is not None:
    img_array = np.array(st.session_state['original_image'])
    st.sidebar.subheader("Image Info (Basic)")
    st.sidebar.write(f"Shape: {img_array.shape}")
    st.sidebar.write(f"Channels: {img_array.shape[2] if len(img_array.shape) == 3 else 1}")


# Color Conversions Section
st.sidebar.subheader("Color Conversions")
color_conversion = st.sidebar.selectbox("Select Conversion", ["None", "RGB to BGR", "BGR to RGB", "RGB to HSV", "HSV to RGB", "RGB to YCbCr", "YCbCr to RGB", "RGB to Grayscale"], key='color_conversion')

if st.session_state['original_image'] is not None and color_conversion != "None":
    img_array = np.array(st.session_state['original_image'])
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)

    processed_img_array = None

    if color_conversion == "RGB to BGR":
        processed_img_array = img_array_bgr # Already in BGR for processing
    elif color_conversion == "BGR to RGB":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2RGB)
    elif color_conversion == "RGB to HSV":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2HSV)
    elif color_conversion == "HSV to RGB":
        img_array_hsv = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2HSV)
        processed_img_array = cv2.cvtColor(img_array_hsv, cv2.COLOR_HSV2RGB)
    elif color_conversion == "RGB to YCbCr":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2YCR_CB)
    elif color_conversion == "YCbCr to RGB":
        img_array_ycbcr = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2YCR_CB)
        processed_img_array = cv2.cvtColor(img_array_ycbcr, cv2.COLOR_YCR_CB2RGB)
    elif color_conversion == "RGB to Grayscale":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2GRAY)

    if processed_img_array is not None:
        if len(processed_img_array.shape) == 2:
             st.session_state['processed_image'] = Image.fromarray(processed_img_array, 'L')
        else:
            # Assuming color conversions result in BGR, convert to RGB for PIL display
             st.session_state['processed_image'] = Image.fromarray(cv2.cvtColor(processed_img_array, cv2.COLOR_BGR2RGB))
        st.session_state['processed_image_caption'] = f"Processed Image ({color_conversion})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"


st.sidebar.title("Transformations")
transformation_type = st.sidebar.selectbox("Select Transformation", ["None", "Rotation", "Scaling", "Translation", "Affine Transform", "Perspective Transform"], key='transformation_type')

if st.session_state['original_image'] is not None and transformation_type != "None":
    img_array = np.array(st.session_state['original_image'])
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
    rows, cols, _ = img_array_bgr.shape
    transformed_img_array = None

    if transformation_type == "Rotation":
        angle = st.sidebar.slider("Angle (degrees)", -180, 180, 0, key='rot_angle')
        M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)
        transformed_img_array = cv2.warpAffine(img_array_bgr, M, (cols, rows))
    elif transformation_type == "Scaling":
        scale_x = st.sidebar.slider("Scale X", 0.1, 5.0, 1.0, key='scale_x')
        scale_y = st.sidebar.slider("Scale Y", 0.1, 5.0, 1.0, key='scale_y')
        transformed_img_array = cv2.resize(img_array_bgr, None, fx=scale_x, fy=scale_y, interpolation=cv2.INTER_LINEAR)
    elif transformation_type == "Translation":
        tx = st.sidebar.slider("Translate X", -cols, cols, 0, key='trans_x')
        ty = st.sidebar.slider("Translate Y", -rows, rows, 0, key='trans_y')
        M = np.float32([[1, 0, tx], [0, 1, ty]])
        transformed_img_array = cv2.warpAffine(img_array_bgr, M, (cols, rows))
    elif transformation_type == "Affine Transform":
        st.sidebar.write("Using example points for demonstration.")
        pts1 = np.float32([[50,50],[200,50],[50,200]])
        pts2 = np.float32([[10,100],[200,50],[100,250]])
        if pts1.shape == (3, 2) and pts2.shape == (3, 2):
            M = cv2.getAffineTransform(pts1, pts2)
            transformed_img_array = cv2.warpAffine(img_array_bgr, M, (cols, rows))
        else:
             st.sidebar.warning("Invalid coordinates for Affine Transform example.")
             transformed_img_array = img_array_bgr
    elif transformation_type == "Perspective Transform":
        st.sidebar.write("Using example points for demonstration.")
        pts1 = np.float32([[56,65],[368,52],[28,387],[389,390]])
        pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])
        if pts1.shape == (4, 2) and pts2.shape == (4, 2):
            M = cv2.getPerspectiveTransform(pts1, pts2)
            transformed_img_array = cv2.warpPerspective(img_array_bgr, M, (300, 300)) # Output size can be different
        else:
            st.sidebar.warning("Invalid coordinates for Perspective Transform example.")
            transformed_img_array = img_array_bgr

    if transformed_img_array is not None:
         st.session_state['processed_image'] = Image.fromarray(cv2.cvtColor(transformed_img_array, cv2.COLOR_BGR2RGB))
         st.session_state['processed_image_caption'] = f"Processed Image ({transformation_type})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"

st.sidebar.title("Filtering & Morphology")
filter_morph_type = st.sidebar.selectbox("Select Operation", ["None", "Gaussian Blur", "Mean Blur", "Median Blur", "Sobel X", "Sobel Y", "Laplacian", "Dilation", "Erosion", "Opening", "Closing"], key='filter_morph_type')

if st.session_state['original_image'] is not None and filter_morph_type != "None":
    img_array = np.array(st.session_state['original_image'])
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
    filtered_morph_img_array = None

    if filter_morph_type == "Gaussian Blur":
        kernel_size_gaussian = st.sidebar.slider("Kernel Size (Gaussian)", 3, 31, 9, step=2, key='gauss_ksize')
        filtered_morph_img_array = cv2.GaussianBlur(img_array_bgr, (kernel_size_gaussian, kernel_size_gaussian), 0)
    elif filter_morph_type == "Mean Blur":
        kernel_size_mean = st.sidebar.slider("Kernel Size (Mean)", 3, 31, 9, step=2, key='mean_ksize')
        filtered_morph_img_array = cv2.blur(img_array_bgr, (kernel_size_mean, kernel_size_mean))
    elif filter_morph_type == "Median Blur":
        kernel_size_median = st.sidebar.slider("Kernel Size (Median)", 3, 31, 9, step=2, key='median_ksize')
        filtered_morph_img_array = cv2.medianBlur(img_array_bgr, kernel_size_median)
    elif filter_morph_type == "Sobel X":
        kernel_size_sobel_x = st.sidebar.slider("Kernel Size (Sobel X)", 3, 31, 3, step=2, key='sobelx_ksize_fm')
        sobelx = cv2.Sobel(img_array_bgr, cv2.CV_64F, 1, 0, ksize=kernel_size_sobel_x)
        filtered_morph_img_array = cv2.convertScaleAbs(sobelx)
    elif filter_morph_type == "Sobel Y":
        kernel_size_sobel_y = st.sidebar.slider("Kernel Size (Sobel Y)", 3, 31, 3, step=2, key='sobely_ksize_fm')
        sobely = cv2.Sobel(img_array_bgr, cv2.CV_64F, 0, 1, ksize=kernel_size_sobel_y)
        filtered_morph_img_array = cv2.convertScaleAbs(sobely)
    elif filter_morph_type == "Laplacian":
        kernel_size_laplacian = st.sidebar.slider("Kernel Size (Laplacian)", 3, 31, 3, step=2, key='laplacian_ksize_fm')
        laplacian = cv2.Laplacian(img_array_bgr, cv2.CV_64F, ksize=kernel_size_laplacian)
        filtered_morph_img_array = cv2.convertScaleAbs(laplacian)
    elif filter_morph_type in ["Dilation", "Erosion", "Opening", "Closing"]:
        kernel_size_morph = st.sidebar.slider("Kernel Size (Morphology)", 1, 15, 3, key='morph_ksize')
        kernel_shape_morph = st.sidebar.selectbox("Kernel Shape", ["Rectangle", "Ellipse", "Cross"], key='morph_shape')

        if kernel_shape_morph == "Rectangle":
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size_morph, kernel_size_morph))
        elif kernel_shape_morph == "Ellipse":
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size_morph, kernel_size_morph))
        elif kernel_shape_morph == "Cross":
            kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (kernel_size_morph, kernel_size_morph))

        if filter_morph_type == "Dilation":
            filtered_morph_img_array = cv2.dilate(img_array_bgr, kernel, iterations=1)
        elif filter_morph_type == "Erosion":
            filtered_morph_img_array = cv2.erode(img_array_bgr, kernel, iterations=1)
        elif filter_morph_type == "Opening":
            filtered_morph_img_array = cv2.morphologyEx(img_array_bgr, cv2.MORPH_OPEN, kernel)
        elif filter_morph_type == "Closing":
            filtered_morph_img_array = cv2.morphologyEx(img_array_bgr, cv2.MORPH_CLOSE, kernel)

    if filtered_morph_img_array is not None:
        if len(filtered_morph_img_array.shape) == 2:
             st.session_state['processed_image'] = Image.fromarray(filtered_morph_img_array, 'L')
        else:
            st.session_state['processed_image'] = Image.fromarray(cv2.cvtColor(filtered_morph_img_array, cv2.COLOR_BGR2RGB))
        st.session_state['processed_image_caption'] = f"Processed Image ({filter_morph_type})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"

st.sidebar.title("Enhancement")
enhancement_type = st.sidebar.selectbox("Select Enhancement", ["None", "Histogram Equalization", "Contrast Stretching", "Sharpening"], key='enhancement_type')

if st.session_state['original_image'] is not None and enhancement_type != "None":
    img_array = np.array(st.session_state['original_image'])
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
    enhanced_img_array = None

    if enhancement_type == "Histogram Equalization":
        if len(img_array_bgr.shape) == 3:
            gray_img = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2GRAY)
        else:
            gray_img = img_array_bgr
        equalized_img = cv2.equalizeHist(gray_img)
        if len(img_array_bgr.shape) == 3:
            enhanced_img_array = cv2.cvtColor(equalized_img, cv2.COLOR_GRAY2BGR)
        else:
            enhanced_img_array = equalized_img
    elif enhancement_type == "Contrast Stretching":
        enhanced_img_array = cv2.normalize(img_array_bgr, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)
    elif enhancement_type == "Sharpening":
        kernel_sharpening = np.array([[-1,-1,-1], [-1, 9,-1], [-1,-1,-1]])
        enhanced_img_array = cv2.filter2D(img_array_bgr, -1, kernel_sharpening)

    if enhanced_img_array is not None:
        if len(enhanced_img_array.shape) == 2:
             st.session_state['processed_image'] = Image.fromarray(enhanced_img_array, 'L')
        else:
            st.session_state['processed_image'] = Image.fromarray(cv2.cvtColor(enhanced_img_array, cv2.COLOR_BGR2RGB))
        st.session_state['processed_image_caption'] = f"Processed Image ({enhancement_type})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"


st.sidebar.title("Edge Detection")
edge_detection_type = st.sidebar.selectbox("Select Edge Detection", ["None", "Sobel", "Canny", "Laplacian"], key='edge_detection_type')

if st.session_state['original_image'] is not None and edge_detection_type != "None":
    img_array = np.array(st.session_state['original_image'])
    if len(img_array.shape) == 3:
        gray_img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
    else:
        gray_img_array = img_array

    edge_detected_img_array = None

    if edge_detection_type == "Sobel":
        sobel_x = st.sidebar.checkbox("Detect X edges", value=True, key='sobel_x_edge')
        sobel_y = st.sidebar.checkbox("Detect Y edges", value=True, key='sobel_y_edge')
        kernel_size_sobel = st.sidebar.slider("Kernel Size (Sobel)", 3, 31, 3, step=2, key='sobel_ksize_edge')
        if sobel_x and sobel_y:
            sobelx = cv2.Sobel(gray_img_array, cv2.CV_64F, 1, 0, ksize=kernel_size_sobel)
            sobely = cv2.Sobel(gray_img_array, cv2.CV_64F, 0, 1, ksize=kernel_size_sobel)
            sobel_combined = np.sqrt(sobelx**2 + sobely**2)
            edge_detected_img_array = cv2.convertScaleAbs(sobel_combined)
        elif sobel_x:
            sobelx = cv2.Sobel(gray_img_array, cv2.CV_64F, 1, 0, ksize=kernel_size_sobel)
            edge_detected_img_array = cv2.convertScaleAbs(sobelx)
        elif sobel_y:
            sobely = cv2.Sobel(gray_img_array, cv2.CV_64F, 0, 1, ksize=kernel_size_sobel)
            edge_detected_img_array = cv2.convertScaleAbs(sobely)
        else:
             edge_detected_img_array = gray_img_array
    elif edge_detection_type == "Canny":
        threshold1 = st.sidebar.slider("Threshold 1 (Canny)", 0, 255, 100, key='canny_thresh1')
        threshold2 = st.sidebar.slider("Threshold 2 (Canny)", 0, 255, 200, key='canny_thresh2')
        aperture_size = st.sidebar.slider("Aperture Size (Canny)", 3, 7, 3, step=2, key='canny_aperture')
        L2gradient = st.sidebar.checkbox("Use L2 gradient", value=False, key='canny_l2')
        edge_detected_img_array = cv2.Canny(gray_img_array, threshold1, threshold2, apertureSize=aperture_size, L2gradient=L2gradient)
    elif edge_detection_type == "Laplacian":
        kernel_size_laplacian = st.sidebar.slider("Kernel Size (Laplacian)", 1, 31, 3, step=2, key='laplacian_ksize_edge')
        laplacian = cv2.Laplacian(gray_img_array, cv2.CV_64F, ksize=kernel_size_laplacian)
        edge_detected_img_array = cv2.convertScaleAbs(laplacian)

    if edge_detected_img_array is not None:
        st.session_state['processed_image'] = Image.fromarray(edge_detected_img_array, 'L')
        st.session_state['processed_image_caption'] = f"Processed Image ({edge_detection_type})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"


# Main content area (for displaying images and results)
st.subheader("Image Display Area")

if st.session_state['original_image'] is not None:
    col1, col2 = st.columns(2)
    with col1:
        st.image(st.session_state['original_image'], caption="Original Image", use_column_width=True)
    with col2:
        if st.session_state['processed_image'] is not None:
            st.image(st.session_state['processed_image'], caption=st.session_state['processed_image_caption'], use_column_width=True)
        else:
            st.write("Apply an operation to see the processed image.")

import streamlit as st
from PIL import Image
import numpy as np
import cv2

st.set_page_config(layout="wide")

st.title("Image Processing Application")

# Use Streamlit's session state to manage the original and processed images
if 'original_image' not in st.session_state:
    st.session_state['original_image'] = None
if 'processed_image' not in st.session_state:
    st.session_state['processed_image'] = None
if 'processed_image_caption' not in st.session_state:
     st.session_state['processed_image_caption'] = "Processed Image"


# Sidebar for operations
st.sidebar.title("Operations")

# Image upload widget
uploaded_file = st.sidebar.file_uploader("Choose an image...", type=["jpg", "jpeg", "png", "bmp", "tiff"], key='file_uploader')

if uploaded_file is not None:
    image = Image.open(uploaded_file)
    st.session_state['original_image'] = image
    st.session_state['processed_image'] = image # Initially, processed is the same as original
    st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"

# Image Info Section (basic - shape and channels for now, full info in a later step)
if st.session_state['original_image'] is not None:
    img_array = np.array(st.session_state['original_image'])
    st.sidebar.subheader("Image Info (Basic)")
    st.sidebar.write(f"Shape: {img_array.shape}")
    st.sidebar.write(f"Channels: {img_array.shape[2] if len(img_array.shape) == 3 else 1}")


st.sidebar.title("Enhancement")
enhancement_type = st.sidebar.selectbox("Select Enhancement", ["None", "Histogram Equalization", "Contrast Stretching", "Sharpening"], key='enhancement_type')

if st.session_state['original_image'] is not None and enhancement_type != "None":
    img_array = np.array(st.session_state['original_image'])
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
    enhanced_img_array = None

    if enhancement_type == "Histogram Equalization":
        if len(img_array_bgr.shape) == 3:
            gray_img = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2GRAY)
        else:
            gray_img = img_array_bgr
        equalized_img = cv2.equalizeHist(gray_img)
        if len(img_array_bgr.shape) == 3:
            enhanced_img_array = cv2.cvtColor(equalized_img, cv2.COLOR_GRAY2BGR)
        else:
            enhanced_img_array = equalized_img
    elif enhancement_type == "Contrast Stretching":
        enhanced_img_array = cv2.normalize(img_array_bgr, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)
    elif enhancement_type == "Sharpening":
        kernel_sharpening = np.array([[-1,-1,-1], [-1, 9,-1], [-1,-1,-1]])
        enhanced_img_array = cv2.filter2D(img_array_bgr, -1, kernel_sharpening)

    if enhanced_img_array is not None:
        if len(enhanced_img_array.shape) == 2:
             st.session_state['processed_image'] = Image.fromarray(enhanced_img_array, 'L')
        else:
            st.session_state['processed_image'] = Image.fromarray(cv2.cvtColor(enhanced_img_array, cv2.COLOR_BGR2RGB))
        st.session_state['processed_image_caption'] = f"Processed Image ({enhancement_type})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"


st.sidebar.title("Edge Detection")
edge_detection_type = st.sidebar.selectbox("Select Edge Detection", ["None", "Sobel", "Canny", "Laplacian"], key='edge_detection_type')

if st.session_state['original_image'] is not None and edge_detection_type != "None":
    img_array = np.array(st.session_state['original_image'])
    if len(img_array.shape) == 3:
        gray_img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
    else:
        gray_img_array = img_array

    edge_detected_img_array = None

    if edge_detection_type == "Sobel":
        sobel_x = st.sidebar.checkbox("Detect X edges", value=True, key='sobel_x_edge')
        sobel_y = st.sidebar.checkbox("Detect Y edges", value=True, key='sobel_y_edge')
        kernel_size_sobel = st.sidebar.slider("Kernel Size (Sobel)", 3, 31, 3, step=2, key='sobel_ksize_edge')
        if sobel_x and sobel_y:
            sobelx = cv2.Sobel(gray_img_array, cv2.CV_64F, 1, 0, ksize=kernel_size_sobel)
            sobely = cv2.Sobel(gray_img_array, cv2.CV_64F, 0, 1, ksize=kernel_size_sobel)
            sobel_combined = np.sqrt(sobelx**2 + sobely**2)
            edge_detected_img_array = cv2.convertScaleAbs(sobel_combined)
        elif sobel_x:
            sobelx = cv2.Sobel(gray_img_array, cv2.CV_64F, 1, 0, ksize=kernel_size_sobel)
            edge_detected_img_array = cv2.convertScaleAbs(sobelx)
        elif sobel_y:
            sobely = cv2.Sobel(gray_img_array, cv2.CV_64F, 0, 1, ksize=kernel_size_sobel)
            edge_detected_img_array = cv2.convertScaleAbs(sobely)
        else:
             edge_detected_img_array = gray_img_array
    elif edge_detection_type == "Canny":
        threshold1 = st.sidebar.slider("Threshold 1 (Canny)", 0, 255, 100, key='canny_thresh1')
        threshold2 = st.sidebar.slider("Threshold 2 (Canny)", 0, 255, 200, key='canny_thresh2')
        aperture_size = st.sidebar.slider("Aperture Size (Canny)", 3, 7, 3, step=2, key='canny_aperture')
        L2gradient = st.sidebar.checkbox("Use L2 gradient", value=False, key='canny_l2')
        edge_detected_img_array = cv2.Canny(gray_img_array, threshold1, threshold2, apertureSize=aperture_size, L2gradient=L2gradient)
    elif edge_detection_type == "Laplacian":
        kernel_size_laplacian = st.sidebar.slider("Kernel Size (Laplacian)", 1, 31, 3, step=2, key='laplacian_ksize_edge')
        laplacian = cv2.Laplacian(gray_img_array, cv2.CV_64F, ksize=kernel_size_laplacian)
        edge_detected_img_array = cv2.convertScaleAbs(laplacian)

    if edge_detected_img_array is not None:
        st.session_state['processed_image'] = Image.fromarray(edge_detected_img_array, 'L')
        st.session_state['processed_image_caption'] = f"Processed Image ({edge_detection_type})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"


# Main content area (for displaying images and results)
st.subheader("Image Display Area")

if st.session_state['original_image'] is not None:
    col1, col2 = st.columns(2)
    with col1:
        st.image(st.session_state['original_image'], caption="Original Image", use_column_width=True)
    with col2:
        if st.session_state['processed_image'] is not None:
            st.image(st.session_state['processed_image'], caption=st.session_state['processed_image_caption'], use_column_width=True)
        else:
            st.write("Apply an operation to see the processed image.")

"""
Phase 6 ‚Äì Compression & File Handling
Save image in different formats (JPG, PNG, BMP)
Compare sizes in the status bar"""

import streamlit as st
from PIL import Image
import numpy as np
import cv2
import io

st.set_page_config(layout="wide")

st.title("Image Processing Application")

# Use Streamlit's session state to manage the original and processed images
if 'original_image' not in st.session_state:
    st.session_state['original_image'] = None
if 'processed_image' not in st.session_state:
    st.session_state['processed_image'] = None
if 'processed_image_caption' not in st.session_state:
     st.session_state['processed_image_caption'] = "Processed Image"


# Menu Bar
st.sidebar.title("Menu")

# File operations
file_operation = st.sidebar.selectbox("File", ["", "Open", "Save As", "Exit"], key='file_op_main')

if file_operation == "Open":
    uploaded_file = st.sidebar.file_uploader("Choose an image...", type=["jpg", "jpeg", "png", "bmp", "tiff"], key='file_uploader_main')
    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        st.session_state['original_image'] = image
        st.session_state['processed_image'] = image # Initially, processed is the same as original
        st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"
elif file_operation == "Save As":
    if st.session_state['processed_image'] is not None:
        st.sidebar.subheader("Save Options")
        output_format = st.sidebar.selectbox("Select output format", ["PNG", "JPEG", "BMP"], key='save_format')

        img_byte_arr = io.BytesIO()
        file_extension = "png"
        mime_type = "image/png"

        if output_format == "JPEG":
            jpeg_quality = st.sidebar.slider("JPEG Quality", 0, 100, 95, key='jpeg_quality')
            st.session_state['processed_image'].save(img_byte_arr, format='JPEG', quality=jpeg_quality)
            file_extension = "jpg"
            mime_type = "image/jpeg"
        elif output_format == "PNG":
             st.session_state['processed_image'].save(img_byte_arr, format='PNG')
             file_extension = "png"
             mime_type = "image/png"
        elif output_format == "BMP":
             st.session_state['processed_image'].save(img_byte_arr, format='BMP')
             file_extension = "bmp"
             mime_type = "image/bmp"

        st.sidebar.download_button(
            label=f"Download Image as {output_format}",
            data=img_byte_arr.getvalue(),
            file_name=f"processed_image.{file_extension}",
            mime=mime_type,
            key='download_button'
        )
        st.sidebar.write(f"File size: {len(img_byte_arr.getvalue()) / 1024:.2f} KB")

    else:
        st.sidebar.warning("No image to save. Please open an image first.")

elif file_operation == "Exit":
    st.stop()


# Sidebar Sections (Organized)
st.sidebar.title("Image Info")
if st.session_state['original_image'] is not None:
    img_info = st.session_state['original_image']
    st.sidebar.write(f"Resolution: {img_info.width} x {img_info.height}")
    st.sidebar.write(f"Shape: {np.array(img_info).shape}")
    if img_info.info and 'dpi' in img_info.info:
        st.sidebar.write(f"DPI: {img_info.info['dpi']}")
    else:
        st.sidebar.write("DPI: N/A")
    st.sidebar.write(f"Format: {img_info.format}")
    st.sidebar.write(f"Channels: {len(img_info.getbands())}")
else:
    st.sidebar.write("No image loaded yet.")


st.sidebar.title("Color Conversions")
color_conversion = st.sidebar.selectbox("Select Conversion", ["None", "RGB to BGR", "BGR to RGB", "RGB to HSV", "HSV to RGB", "RGB to YCbCr", "YCbCr to RGB", "RGB to Grayscale"], key='color_conversion')

if st.session_state['original_image'] is not None and color_conversion != "None":
    img_array = np.array(st.session_state['original_image'])
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)

    processed_img_array = None

    if color_conversion == "RGB to BGR":
        processed_img_array = img_array_bgr # Already in BGR for processing
    elif color_conversion == "BGR to RGB":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2RGB)
    elif color_conversion == "RGB to HSV":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2HSV)
    elif color_conversion == "HSV to RGB":
        img_array_hsv = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2HSV)
        processed_img_array = cv2.cvtColor(img_array_hsv, cv2.COLOR_HSV2RGB)
    elif color_conversion == "RGB to YCbCr":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2YCR_CB)
    elif color_conversion == "YCbCr to RGB":
        img_array_ycbcr = cv2.cvtColor(img_array_bgr, cv2.COLOR_YCR_CB2RGB)
        processed_img_array = cv2.cvtColor(img_array_ycbcr, cv2.COLOR_YCR_CB2RGB)
    elif color_conversion == "RGB to Grayscale":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2GRAY)

    if processed_img_array is not None:
        if len(processed_img_array.shape) == 2:
             st.session_state['processed_image'] = Image.fromarray(processed_img_array, 'L')
        else:
            # Assuming color conversions result in BGR, convert to RGB for PIL display
             st.session_state['processed_image'] = Image.fromarray(cv2.cvtColor(processed_img_array, cv2.COLOR_BGR2RGB))
        st.session_state['processed_image_caption'] = f"Processed Image ({color_conversion})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"


st.sidebar.title("Transformations")
transformation_type = st.sidebar.selectbox("Select Transformation", ["None", "Rotation", "Scaling", "Translation", "Affine Transform", "Perspective Transform"], key='transformation_type')

if st.session_state['original_image'] is not None and transformation_type != "None":
    img_array = np.array(st.session_state['original_image'])
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
    rows, cols, _ = img_array_bgr.shape
    transformed_img_array = None

    if transformation_type == "Rotation":
        angle = st.sidebar.slider("Angle (degrees)", -180, 180, 0, key='rot_angle')
        M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)
        transformed_img_array = cv2.warpAffine(img_array_bgr, M, (cols, rows))
    elif transformation_type == "Scaling":
        scale_x = st.sidebar.slider("Scale X", 0.1, 5.0, 1.0, key='scale_x')
        scale_y = st.sidebar.slider("Scale Y", 0.1, 5.0, 1.0, key='scale_y')
        transformed_img_array = cv2.resize(img_array_bgr, None, fx=scale_x, fy=scale_y, interpolation=cv2.INTER_LINEAR)
    elif transformation_type == "Translation":
        tx = st.sidebar.slider("Translate X", -cols, cols, 0, key='trans_x')
        ty = st.sidebar.slider("Translate Y", -rows, rows, 0, key='trans_y')
        M = np.float32([[1, 0, tx], [0, 1, ty]])
        transformed_img_array = cv2.warpAffine(img_array_bgr, M, (cols, rows))
    elif transformation_type == "Affine Transform":
        st.sidebar.write("Using example points for demonstration.")
        pts1 = np.float32([[50,50],[200,50],[50,200]])
        pts2 = np.float32([[10,100],[200,50],[100,250]])
        if pts1.shape == (3, 2) and pts2.shape == (3, 2):
            M = cv2.getAffineTransform(pts1, pts2)
            transformed_img_array = cv2.warpAffine(img_array_bgr, M, (cols, rows))
        else:
             st.sidebar.warning("Invalid coordinates for Affine Transform example.")
             transformed_img_array = img_array_bgr
    elif transformation_type == "Perspective Transform":
        st.sidebar.write("Using example points for demonstration.")
        pts1 = np.float32([[56,65],[368,52],[28,387],[389,390]])
        pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])
        if pts1.shape == (4, 2) and pts2.shape == (4, 2):
            M = cv2.getPerspectiveTransform(pts1, pts2)
            transformed_img_array = cv2.warpPerspective(img_array_bgr, M, (300, 300)) # Output size can be different
        else:
            st.sidebar.warning("Invalid coordinates for Perspective Transform example.")
            transformed_img_array = img_array_bgr

    if transformed_img_array is not None:
         st.session_state['processed_image'] = Image.fromarray(cv2.cvtColor(transformed_img_array, cv2.COLOR_BGR2RGB))
         st.session_state['processed_image_caption'] = f"Processed Image ({transformation_type})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"

st.sidebar.title("Filtering & Morphology")
filter_morph_type = st.sidebar.selectbox("Select Operation", ["None", "Gaussian Blur", "Mean Blur", "Median Blur", "Sobel X", "Sobel Y", "Laplacian", "Dilation", "Erosion", "Opening", "Closing"], key='filter_morph_type')

if st.session_state['original_image'] is not None and filter_morph_type != "None":
    img_array = np.array(st.session_state['original_image'])
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
    filtered_morph_img_array = None

    if filter_morph_type == "Gaussian Blur":
        kernel_size_gaussian = st.sidebar.slider("Kernel Size (Gaussian)", 3, 31, 9, step=2, key='gauss_ksize')
        filtered_morph_img_array = cv2.GaussianBlur(img_array_bgr, (kernel_size_gaussian, kernel_size_gaussian), 0)
    elif filter_morph_type == "Mean Blur":
        kernel_size_mean = st.sidebar.slider("Kernel Size (Mean)", 3, 31, 9, step=2, key='mean_ksize')
        filtered_morph_img_array = cv2.blur(img_array_bgr, (kernel_size_mean, kernel_size_mean))
    elif filter_morph_type == "Median Blur":
        kernel_size_median = st.sidebar.slider("Kernel Size (Median)", 3, 31, 9, step=2, key='median_ksize')
        filtered_morph_img_array = cv2.medianBlur(img_array_bgr, kernel_size_median)
    elif filter_morph_type == "Sobel X":
        kernel_size_sobel_x = st.sidebar.slider("Kernel Size (Sobel X)", 3, 31, 3, step=2, key='sobelx_ksize_fm')
        sobelx = cv2.Sobel(img_array_bgr, cv2.CV_64F, 1, 0, ksize=kernel_size_sobel_x)
        filtered_morph_img_array = cv2.convertScaleAbs(sobelx)
    elif filter_morph_type == "Sobel Y":
        kernel_size_sobel_y = st.sidebar.slider("Kernel Size (Sobel Y)", 3, 31, 3, step=2, key='sobely_ksize_fm')
        sobely = cv2.Sobel(img_array_bgr, cv2.CV_64F, 0, 1, ksize=kernel_size_sobel_y)
        filtered_morph_img_array = cv2.convertScaleAbs(sobely)
    elif filter_morph_type == "Laplacian":
        kernel_size_laplacian = st.sidebar.slider("Kernel Size (Laplacian)", 3, 31, 3, step=2, key='laplacian_ksize_fm')
        laplacian = cv2.Laplacian(img_array_bgr, cv2.CV_64F, ksize=kernel_size_laplacian)
        filtered_morph_img_array = cv2.convertScaleAbs(laplacian)
    elif filter_morph_type in ["Dilation", "Erosion", "Opening", "Closing"]:
        kernel_size_morph = st.sidebar.slider("Kernel Size (Morphology)", 1, 15, 3, key='morph_ksize')
        kernel_shape_morph = st.sidebar.selectbox("Kernel Shape", ["Rectangle", "Ellipse", "Cross"], key='morph_shape')

        if kernel_shape_morph == "Rectangle":
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size_morph, kernel_size_morph))
        elif kernel_shape_morph == "Ellipse":
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size_morph, kernel_size_morph))
        elif kernel_shape_morph == "Cross":
            kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (kernel_size_morph, kernel_size_morph))

        if filter_morph_type == "Dilation":
            filtered_morph_img_array = cv2.dilate(img_array_bgr, kernel, iterations=1)
        elif filter_morph_type == "Erosion":
            filtered_morph_img_array = cv2.erode(img_array_bgr, kernel, iterations=1)
        elif filter_morph_type == "Opening":
            filtered_morph_img_array = cv2.morphologyEx(img_array_bgr, cv2.MORPH_OPEN, kernel)
        elif filter_morph_type == "Closing":
            filtered_morph_img_array = cv2.morphologyEx(img_array_bgr, cv2.MORPH_CLOSE, kernel)

    if filtered_morph_img_array is not None:
        if len(filtered_morph_img_array.shape) == 2:
             st.session_state['processed_image'] = Image.fromarray(filtered_morph_img_array, 'L')
        else:
            st.session_state['processed_image'] = Image.fromarray(cv2.cvtColor(filtered_morph_img_array, cv2.COLOR_BGR2RGB))
        st.session_state['processed_image_caption'] = f"Processed Image ({filter_morph_type})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"

st.sidebar.title("Enhancement")
enhancement_type = st.sidebar.selectbox("Select Enhancement", ["None", "Histogram Equalization", "Contrast Stretching", "Sharpening"], key='enhancement_type')

if st.session_state['original_image'] is not None and enhancement_type != "None":
    img_array = np.array(st.session_state['original_image'])
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
    enhanced_img_array = None

    if enhancement_type == "Histogram Equalization":
        if len(img_array_bgr.shape) == 3:
            gray_img = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2GRAY)
        else:
            gray_img = img_array_bgr
        equalized_img = cv2.equalizeHist(gray_img)
        if len(img_array_bgr.shape) == 3:
            enhanced_img_array = cv2.cvtColor(equalized_img, cv2.COLOR_GRAY2BGR)
        else:
            enhanced_img_array = equalized_img
    elif enhancement_type == "Contrast Stretching":
        enhanced_img_array = cv2.normalize(img_array_bgr, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)
    elif enhancement_type == "Sharpening":
        kernel_sharpening = np.array([[-1,-1,-1], [-1, 9,-1], [-1,-1,-1]])
        enhanced_img_array = cv2.filter2D(img_array_bgr, -1, kernel_sharpening)

    if enhanced_img_array is not None:
        if len(enhanced_img_array.shape) == 2:
             st.session_state['processed_image'] = Image.fromarray(enhanced_img_array, 'L')
        else:
            st.session_state['processed_image'] = Image.fromarray(cv2.cvtColor(enhanced_img_array, cv2.COLOR_BGR2RGB))
        st.session_state['processed_image_caption'] = f"Processed Image ({enhancement_type})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"


st.sidebar.title("Edge Detection")
edge_detection_type = st.sidebar.selectbox("Select Edge Detection", ["None", "Sobel", "Canny", "Laplacian"], key='edge_detection_type')

if st.session_state['original_image'] is not None and edge_detection_type != "None":
    img_array = np.array(st.session_state['original_image'])
    if len(img_array.shape) == 3:
        gray_img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
    else:
        gray_img_array = img_array

    edge_detected_img_array = None

    if edge_detection_type == "Sobel":
        sobel_x = st.sidebar.checkbox("Detect X edges", value=True, key='sobel_x_edge')
        sobel_y = st.sidebar.checkbox("Detect Y edges", value=True, key='sobel_y_edge')
        kernel_size_sobel = st.sidebar.slider("Kernel Size (Sobel)", 3, 31, 3, step=2, key='sobel_ksize_edge')
        if sobel_x and sobel_y:
            sobelx = cv2.Sobel(gray_img_array, cv2.CV_64F, 1, 0, ksize=kernel_size_sobel)
            sobely = cv2.Sobel(gray_img_array, cv2.CV_64F, 0, 1, ksize=kernel_size_sobel)
            sobel_combined = np.sqrt(sobelx**2 + sobely**2)
            edge_detected_img_array = cv2.convertScaleAbs(sobel_combined)
        elif sobel_x:
            sobelx = cv2.Sobel(gray_img_array, cv2.CV_64F, 1, 0, ksize=kernel_size_sobel)
            edge_detected_img_array = cv2.convertScaleAbs(sobelx)
        elif sobel_y:
            sobely = cv2.Sobel(gray_img_array, cv2.CV_64F, 0, 1, ksize=kernel_size_sobel)
            edge_detected_img_array = cv2.convertScaleAbs(sobely)
        else:
             edge_detected_img_array = gray_img_array
    elif edge_detection_type == "Canny":
        threshold1 = st.sidebar.slider("Threshold 1 (Canny)", 0, 255, 100, key='canny_thresh1')
        threshold2 = st.sidebar.slider("Threshold 2 (Canny)", 0, 255, 200, key='canny_thresh2')
        aperture_size = st.sidebar.slider("Aperture Size (Canny)", 3, 7, 3, step=2, key='canny_aperture')
        L2gradient = st.sidebar.checkbox("Use L2 gradient", value=False, key='canny_l2')
        edge_detected_img_array = cv2.Canny(gray_img_array, threshold1, threshold2, apertureSize=aperture_size, L2gradient=L2gradient)
    elif edge_detection_type == "Laplacian":
        kernel_size_laplacian = st.sidebar.slider("Kernel Size (Laplacian)", 1, 31, 3, step=2, key='laplacian_ksize_edge')
        laplacian = cv2.Laplacian(gray_img_array, cv2.CV_64F, ksize=kernel_size_laplacian)
        edge_detected_img_array = cv2.convertScaleAbs(laplacian)

    if edge_detected_img_array is not None:
        st.session_state['processed_image'] = Image.fromarray(edge_detected_img_array, 'L')
        st.session_state['processed_image_caption'] = f"Processed Image ({edge_detection_type})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"


# Main content area (for displaying images and results)
st.subheader("Image Display Area")

if st.session_state['original_image'] is not None:
    col1, col2 = st.columns(2)
    with col1:
        st.image(st.session_state['original_image'], caption="Original Image", use_column_width=True)
    with col2:
        if st.session_state['processed_image'] is not None:
            st.image(st.session_state['processed_image'], caption=st.session_state['processed_image_caption'], use_column_width=True)
        else:
            st.write("Apply an operation to see the processed image.")

# Status Bar
st.subheader("Status")
if st.session_state['original_image'] is not None:
    img_info = st.session_state['processed_image'] if st.session_state['processed_image'] is not None else st.session_state['original_image']
    img_array = np.array(img_info)
    height, width = img_array.shape[:2]
    channels = img_array.shape[2] if len(img_array.shape) == 3 else 1
    dpi = img_info.info.get('dpi', 'N/A')
    format = img_info.format

    # To get file size, we need to save the image to a BytesIO object first
    img_byte_arr = io.BytesIO()
    try:
        img_info.save(img_byte_arr, format=format if format else 'PNG') # Use PNG if format is None
        file_size = len(img_byte_arr.getvalue()) / 1024 # size in KB
        st.write(f"Dimensions: {width} x {height} x {channels} | DPI/PPI: {dpi} | Format: {format if format else 'N/A'} | File Size: {file_size:.2f} KB")
    except Exception as e:
        st.write(f"Dimensions: {width} x {height} x {channels} | DPI/PPI: {dpi} | Format: {format if format else 'N/A'} | File Size: Could not determine ({e})")
else:
    st.write("Load an image to see status information.")

"""
Phase 7 ‚Äì Polish the GUI
Add status bar (image info updates after each operation)
Add Save Processed Image button
Make layout clean: two columns for original vs processed image"""

import streamlit as st
from PIL import Image
import numpy as np
import cv2
import io

st.set_page_config(layout="wide")

st.title("Image Processing Application")

# Use Streamlit's session state to manage the original and processed images
if 'original_image' not in st.session_state:
    st.session_state['original_image'] = None
if 'processed_image' not in st.session_state:
    st.session_state['processed_image'] = None
if 'processed_image_caption' not in st.session_state:
     st.session_state['processed_image_caption'] = "Processed Image"


# Menu Bar
st.sidebar.title("Menu")

# File operations
file_operation = st.sidebar.selectbox("File", ["", "Open", "Save As", "Exit"], key='file_op_main')

if file_operation == "Open":
    uploaded_file = st.sidebar.file_uploader("Choose an image...", type=["jpg", "jpeg", "png", "bmp", "tiff"], key='file_uploader_main')
    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        st.session_state['original_image'] = image
        st.session_state['processed_image'] = image # Initially, processed is the same as original
        st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"
elif file_operation == "Save As":
    if st.session_state['processed_image'] is not None:
        st.sidebar.subheader("Save Options")
        output_format = st.sidebar.selectbox("Select output format", ["PNG", "JPEG", "BMP"], key='save_format')

        img_byte_arr = io.BytesIO()
        file_extension = "png"
        mime_type = "image/png"

        if output_format == "JPEG":
            jpeg_quality = st.sidebar.slider("JPEG Quality", 0, 100, 95, key='jpeg_quality')
            st.session_state['processed_image'].save(img_byte_arr, format='JPEG', quality=jpeg_quality)
            file_extension = "jpg"
            mime_type = "image/jpeg"
        elif output_format == "PNG":
             st.session_state['processed_image'].save(img_byte_arr, format='PNG')
             file_extension = "png"
             mime_type = "image/png"
        elif output_format == "BMP":
             st.session_state['processed_image'].save(img_byte_arr, format='BMP')
             file_extension = "bmp"
             mime_type = "image/bmp"

        st.sidebar.download_button(
            label=f"Download Image as {output_format}",
            data=img_byte_arr.getvalue(),
            file_name=f"processed_image.{file_extension}",
            mime=mime_type,
            key='download_button'
        )
        st.sidebar.write(f"File size: {len(img_byte_arr.getvalue()) / 1024:.2f} KB")

    else:
        st.sidebar.warning("No image to save. Please open an image first.")

elif file_operation == "Exit":
    st.stop()


# Sidebar Sections (Organized)
st.sidebar.title("Image Info")
if st.session_state['original_image'] is not None:
    img_info = st.session_state['original_image']
    st.sidebar.write(f"Resolution: {img_info.width} x {img_info.height}")
    st.sidebar.write(f"Shape: {np.array(img_info).shape}")
    if img_info.info and 'dpi' in img_info.info:
        st.sidebar.write(f"DPI: {img_info.info['dpi']}")
    else:
        st.sidebar.write("DPI: N/A")
    st.sidebar.write(f"Format: {img_info.format}")
    st.sidebar.write(f"Channels: {len(img_info.getbands())}")
else:
    st.sidebar.write("No image loaded yet.")


st.sidebar.title("Color Conversions")
color_conversion = st.sidebar.selectbox("Select Conversion", ["None", "RGB to BGR", "BGR to RGB", "RGB to HSV", "HSV to RGB", "RGB to YCbCr", "YCbCr to RGB", "RGB to Grayscale"], key='color_conversion')

if st.session_state['original_image'] is not None and color_conversion != "None":
    img_array = np.array(st.session_state['original_image'])
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)

    processed_img_array = None

    if color_conversion == "RGB to BGR":
        processed_img_array = img_array_bgr # Already in BGR for processing
    elif color_conversion == "BGR to RGB":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2RGB)
    elif color_conversion == "RGB to HSV":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2HSV)
    elif color_conversion == "HSV to RGB":
        img_array_hsv = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2HSV)
        processed_img_array = cv2.cvtColor(img_array_hsv, cv2.COLOR_HSV2RGB)
    elif color_conversion == "RGB to YCbCr":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2YCR_CB)
    elif color_conversion == "YCbCr to RGB":
        img_array_ycbcr = cv2.cvtColor(img_array_bgr, cv2.COLOR_YCR_CB2RGB)
        processed_img_array = cv2.cvtColor(img_array_ycbcr, cv2.COLOR_YCR_CB2RGB)
    elif color_conversion == "RGB to Grayscale":
        processed_img_array = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2GRAY)

    if processed_img_array is not None:
        if len(processed_img_array.shape) == 2:
             st.session_state['processed_image'] = Image.fromarray(processed_img_array, 'L')
        else:
            # Assuming color conversions result in BGR, convert to RGB for PIL display
             st.session_state['processed_image'] = Image.fromarray(cv2.cvtColor(processed_img_array, cv2.COLOR_BGR2RGB))
        st.session_state['processed_image_caption'] = f"Processed Image ({color_conversion})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"


st.sidebar.title("Transformations")
transformation_type = st.sidebar.selectbox("Select Transformation", ["None", "Rotation", "Scaling", "Translation", "Affine Transform", "Perspective Transform"], key='transformation_type')

if st.session_state['original_image'] is not None and transformation_type != "None":
    img_array = np.array(st.session_state['original_image'])
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
    rows, cols, _ = img_array_bgr.shape
    transformed_img_array = None

    if transformation_type == "Rotation":
        angle = st.sidebar.slider("Angle (degrees)", -180, 180, 0, key='rot_angle')
        M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)
        transformed_img_array = cv2.warpAffine(img_array_bgr, M, (cols, rows))
    elif transformation_type == "Scaling":
        scale_x = st.sidebar.slider("Scale X", 0.1, 5.0, 1.0, key='scale_x')
        scale_y = st.sidebar.slider("Scale Y", 0.1, 5.0, 1.0, key='scale_y')
        transformed_img_array = cv2.resize(img_array_bgr, None, fx=scale_x, fy=scale_y, interpolation=cv2.INTER_LINEAR)
    elif transformation_type == "Translation":
        tx = st.sidebar.slider("Translate X", -cols, cols, 0, key='trans_x')
        ty = st.sidebar.slider("Translate Y", -rows, rows, 0, key='trans_y')
        M = np.float32([[1, 0, tx], [0, 1, ty]])
        transformed_img_array = cv2.warpAffine(img_array_bgr, M, (cols, rows))
    elif transformation_type == "Affine Transform":
        st.sidebar.write("Using example points for demonstration.")
        pts1 = np.float32([[50,50],[200,50],[50,200]])
        pts2 = np.float32([[10,100],[200,50],[100,250]])
        if pts1.shape == (3, 2) and pts2.shape == (3, 2):
            M = cv2.getAffineTransform(pts1, pts2)
            transformed_img_array = cv2.warpAffine(img_array_bgr, M, (cols, rows))
        else:
             st.sidebar.warning("Invalid coordinates for Affine Transform example.")
             transformed_img_array = img_array_bgr
    elif transformation_type == "Perspective Transform":
        st.sidebar.write("Using example points for demonstration.")
        pts1 = np.float32([[56,65],[368,52],[28,387],[389,390]])
        pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])
        if pts1.shape == (4, 2) and pts2.shape == (4, 2):
            M = cv2.getPerspectiveTransform(pts1, pts2)
            transformed_img_array = cv2.warpPerspective(img_array_bgr, M, (300, 300)) # Output size can be different
        else:
            st.sidebar.warning("Invalid coordinates for Perspective Transform example.")
            transformed_img_array = img_array_bgr

    if transformed_img_array is not None:
         st.session_state['processed_image'] = Image.fromarray(cv2.cvtColor(transformed_img_array, cv2.COLOR_BGR2RGB))
         st.session_state['processed_image_caption'] = f"Processed Image ({transformation_type})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"

st.sidebar.title("Filtering & Morphology")
filter_morph_type = st.sidebar.selectbox("Select Operation", ["None", "Gaussian Blur", "Mean Blur", "Median Blur", "Sobel X", "Sobel Y", "Laplacian", "Dilation", "Erosion", "Opening", "Closing"], key='filter_morph_type')

if st.session_state['original_image'] is not None and filter_morph_type != "None":
    img_array = np.array(st.session_state['original_image'])
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
    filtered_morph_img_array = None

    if filter_morph_type == "Gaussian Blur":
        kernel_size_gaussian = st.sidebar.slider("Kernel Size (Gaussian)", 3, 31, 9, step=2, key='gauss_ksize')
        filtered_morph_img_array = cv2.GaussianBlur(img_array_bgr, (kernel_size_gaussian, kernel_size_gaussian), 0)
    elif filter_morph_type == "Mean Blur":
        kernel_size_mean = st.sidebar.slider("Kernel Size (Mean)", 3, 31, 9, step=2, key='mean_ksize')
        filtered_morph_img_array = cv2.blur(img_array_bgr, (kernel_size_mean, kernel_size_mean))
    elif filter_morph_type == "Median Blur":
        kernel_size_median = st.sidebar.slider("Kernel Size (Median)", 3, 31, 9, step=2, key='median_ksize')
        filtered_morph_img_array = cv2.medianBlur(img_array_bgr, kernel_size_median)
    elif filter_morph_type == "Sobel X":
        kernel_size_sobel_x = st.sidebar.slider("Kernel Size (Sobel X)", 3, 31, 3, step=2, key='sobelx_ksize_fm')
        sobelx = cv2.Sobel(img_array_bgr, cv2.CV_64F, 1, 0, ksize=kernel_size_sobel_x)
        filtered_morph_img_array = cv2.convertScaleAbs(sobelx)
    elif filter_morph_type == "Sobel Y":
        kernel_size_sobel_y = st.sidebar.slider("Kernel Size (Sobel Y)", 3, 31, 3, step=2, key='sobely_ksize_fm')
        sobely = cv2.Sobel(img_array_bgr, cv2.CV_64F, 0, 1, ksize=kernel_size_sobel_y)
        filtered_morph_img_array = cv2.convertScaleAbs(sobely)
    elif filter_morph_type == "Laplacian":
        kernel_size_laplacian = st.sidebar.slider("Kernel Size (Laplacian)", 3, 31, 3, step=2, key='laplacian_ksize_fm')
        laplacian = cv2.Laplacian(img_array_bgr, cv2.CV_64F, ksize=kernel_size_laplacian)
        filtered_morph_img_array = cv2.convertScaleAbs(laplacian)
    elif filter_morph_type in ["Dilation", "Erosion", "Opening", "Closing"]:
        kernel_size_morph = st.sidebar.slider("Kernel Size (Morphology)", 1, 15, 3, key='morph_ksize')
        kernel_shape_morph = st.sidebar.selectbox("Kernel Shape", ["Rectangle", "Ellipse", "Cross"], key='morph_shape')

        if kernel_shape_morph == "Rectangle":
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size_morph, kernel_size_morph))
        elif kernel_shape_morph == "Ellipse":
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size_morph, kernel_size_morph))
        elif kernel_shape_morph == "Cross":
            kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (kernel_size_morph, kernel_size_morph))

        if filter_morph_type == "Dilation":
            filtered_morph_img_array = cv2.dilate(img_array_bgr, kernel, iterations=1)
        elif filter_morph_type == "Erosion":
            filtered_morph_img_array = cv2.erode(img_array_bgr, kernel, iterations=1)
        elif filter_morph_type == "Opening":
            filtered_morph_img_array = cv2.morphologyEx(img_array_bgr, cv2.MORPH_OPEN, kernel)
        elif filter_morph_type == "Closing":
            filtered_morph_img_array = cv2.morphologyEx(img_array_bgr, cv2.MORPH_CLOSE, kernel)

    if filtered_morph_img_array is not None:
        if len(filtered_morph_img_array.shape) == 2:
             st.session_state['processed_image'] = Image.fromarray(filtered_morph_img_array, 'L')
        else:
            st.session_state['processed_image'] = Image.fromarray(cv2.cvtColor(filtered_morph_img_array, cv2.COLOR_BGR2RGB))
        st.session_state['processed_image_caption'] = f"Processed Image ({filter_morph_type})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"

st.sidebar.title("Enhancement")
enhancement_type = st.sidebar.selectbox("Select Enhancement", ["None", "Histogram Equalization", "Contrast Stretching", "Sharpening"], key='enhancement_type')

if st.session_state['original_image'] is not None and enhancement_type != "None":
    img_array = np.array(st.session_state['original_image'])
    img_array_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
    enhanced_img_array = None

    if enhancement_type == "Histogram Equalization":
        if len(img_array_bgr.shape) == 3:
            gray_img = cv2.cvtColor(img_array_bgr, cv2.COLOR_BGR2GRAY)
        else:
            gray_img = img_array_bgr
        equalized_img = cv2.equalizeHist(gray_img)
        if len(img_array_bgr.shape) == 3:
            enhanced_img_array = cv2.cvtColor(equalized_img, cv2.COLOR_GRAY2BGR)
        else:
            enhanced_img_array = enhanced_img_array # Keep as grayscale if original was grayscale
    elif enhancement_type == "Contrast Stretching":
        enhanced_img_array = cv2.normalize(img_array_bgr, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)
    elif enhancement_type == "Sharpening":
        kernel_sharpening = np.array([[-1,-1,-1], [-1, 9,-1], [-1,-1,-1]])
        enhanced_img_array = cv2.filter2D(img_array_bgr, -1, kernel_sharpening)

    if enhanced_img_array is not None:
        if len(enhanced_img_array.shape) == 2:
             st.session_state['processed_image'] = Image.fromarray(enhanced_img_array, 'L')
        else:
            st.session_state['processed_image'] = Image.fromarray(cv2.cvtColor(enhanced_img_array, cv2.COLOR_BGR2RGB))
        st.session_state['processed_image_caption'] = f"Processed Image ({enhancement_type})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"


st.sidebar.title("Edge Detection")
edge_detection_type = st.sidebar.selectbox("Select Edge Detection", ["None", "Sobel", "Canny", "Laplacian"], key='edge_detection_type')

if st.session_state['original_image'] is not None and edge_detection_type != "None":
    img_array = np.array(st.session_state['original_image'])
    if len(img_array.shape) == 3:
        gray_img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
    else:
        gray_img_array = img_array

    edge_detected_img_array = None

    if edge_detection_type == "Sobel":
        sobel_x = st.sidebar.checkbox("Detect X edges", value=True, key='sobel_x_edge')
        sobel_y = st.sidebar.checkbox("Detect Y edges", value=True, key='sobel_y_edge')
        kernel_size_sobel = st.sidebar.slider("Kernel Size (Sobel)", 3, 31, 3, step=2, key='sobel_ksize_edge')
        if sobel_x and sobel_y:
            sobelx = cv2.Sobel(gray_img_array, cv2.CV_64F, 1, 0, ksize=kernel_size_sobel)
            sobely = cv2.Sobel(gray_img_array, cv2.CV_64F, 0, 1, ksize=kernel_size_sobel)
            sobel_combined = np.sqrt(sobelx**2 + sobely**2)
            edge_detected_img_array = cv2.convertScaleAbs(sobel_combined)
        elif sobel_x:
            sobelx = cv2.Sobel(gray_img_array, cv2.CV_64F, 1, 0, ksize=kernel_size_sobel)
            edge_detected_img_array = cv2.convertScaleAbs(sobelx)
        elif sobel_y:
            sobely = cv2.Sobel(gray_img_array, cv2.CV_64F, 0, 1, ksize=kernel_size_sobel)
            edge_detected_img_array = cv2.convertScaleAbs(sobely)
        else:
             edge_detected_img_array = gray_img_array
    elif edge_detection_type == "Canny":
        threshold1 = st.sidebar.slider("Threshold 1 (Canny)", 0, 255, 100, key='canny_thresh1')
        threshold2 = st.sidebar.slider("Threshold 2 (Canny)", 0, 255, 200, key='canny_thresh2')
        aperture_size = st.sidebar.slider("Aperture Size (Canny)", 3, 7, 3, step=2, key='canny_aperture')
        L2gradient = st.sidebar.checkbox("Use L2 gradient", value=False, key='canny_l2')
        edge_detected_img_array = cv2.Canny(gray_img_array, threshold1, threshold2, apertureSize=aperture_size, L2gradient=L2gradient)
    elif edge_detection_type == "Laplacian":
        kernel_size_laplacian = st.sidebar.slider("Kernel Size (Laplacian)", 1, 31, 3, step=2, key='laplacian_ksize_edge')
        laplacian = cv2.Laplacian(gray_img_array, cv2.CV_64F, ksize=kernel_size_laplacian)
        edge_detected_img_array = cv2.convertScaleAbs(laplacian)

    if edge_detected_img_array is not None:
        st.session_state['processed_image'] = Image.fromarray(edge_detected_img_array, 'L')
        st.session_state['processed_image_caption'] = f"Processed Image ({edge_detection_type})"
    else:
         st.session_state['processed_image'] = st.session_state['original_image']
         st.session_state['processed_image_caption'] = "Original Image (No Operation Applied)"


# Main content area (for displaying images and results)
st.subheader("Image Display Area")

if st.session_state['original_image'] is not None:
    col1, col2 = st.columns(2)
    with col1:
        st.image(st.session_state['original_image'], caption="Original Image", use_column_width=True)
    with col2:
        if st.session_state['processed_image'] is not None:
            st.image(st.session_state['processed_image'], caption=st.session_state['processed_image_caption'], use_column_width=True)
        else:
            st.write("Apply an operation to see the processed image.")

# Status Bar
st.subheader("Status")
if st.session_state['original_image'] is not None:
    img_info = st.session_state['processed_image'] if st.session_state['processed_image'] is not None else st.session_state['original_image']
    img_array = np.array(img_info)
    height, width = img_array.shape[:2]
    channels = img_array.shape[2] if len(img_array.shape) == 3 else 1
    dpi = img_info.info.get('dpi', 'N/A')
    format = img_info.format

    # To get file size, we need to save the image to a BytesIO object first
    img_byte_arr = io.BytesIO()
    try:
        img_info.save(img_byte_arr, format=format if format else 'PNG') # Use PNG if format is None
        file_size = len(img_byte_arr.getvalue()) / 1024 # size in KB
        st.write(f"Dimensions: {width} x {height} x {channels} | DPI/PPI: {dpi} | Format: {format if format else 'N/A'} | File Size: {file_size:.2f} KB")
    except Exception as e:
        st.write(f"Dimensions: {width} x {height} x {channels} | DPI/PPI: {dpi} | Format: {format if format else 'N/A'} | File Size: Could not determine ({e})")
else:
    st.write("Load an image to see status information.")

"""Deliverables
Codebase: app.py (Streamlit GUI app) + utility scripts

Notebook: ImageToolkit.ipynb for step-by-step theory + practice tasks

Report (PDF):

Notes on CMOS vs CCD, Sampling & Quantization, PSFs
Screenshots of toolkit results
Explanation of algorithms used
Final Demo: Interactive Streamlit GUI

The code for the Streamlit GUI application, which will be your app.py file, is currently spread across several cells in this notebook as we've been building it step-by-step.

Generating the complete app.py in this single empty cell isn't the standard way to work in Colab. However, I can consolidate all the Streamlit code we've written so far into one code cell. You can then copy the content of that cell and save it as an app.py file on your local machine to run the full application.
"""